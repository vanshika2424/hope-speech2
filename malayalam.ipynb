{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:20:25.141563Z","iopub.execute_input":"2026-01-04T13:20:25.141776Z","iopub.status.idle":"2026-01-04T13:20:25.958165Z","shell.execute_reply.started":"2026-01-04T13:20:25.141755Z","shell.execute_reply":"2026-01-04T13:20:25.957386Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/malayalam-hope-speech-dataset/malayalam_dev.csv\n/kaggle/input/malayalam-hope-speech-dataset/malayalam_train.csv\n/kaggle/input/malayalam-hope-speech-dataset/malayalam_test.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv(\"/kaggle/input/malayalam-hope-speech-dataset/malayalam_train.csv\",\n                    sep=\"\\t\", header=None)\ndev   = pd.read_csv(\"/kaggle/input/malayalam-hope-speech-dataset/malayalam_dev.csv\",\n                    sep=\"\\t\", header=None)\ntest  = pd.read_csv(\"/kaggle/input/malayalam-hope-speech-dataset/malayalam_test.csv\",\n                    sep=\"\\t\", header=None)\n\ntrain.columns = [\"raw\"]\ndev.columns   = [\"raw\"]\ntest.columns  = [\"raw\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:20:25.959169Z","iopub.execute_input":"2026-01-04T13:20:25.959687Z","iopub.status.idle":"2026-01-04T13:20:26.057373Z","shell.execute_reply.started":"2026-01-04T13:20:25.959663Z","shell.execute_reply":"2026-01-04T13:20:26.056690Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def clean_split(df):\n    parts = df[\"raw\"].str.split(\";\", expand=True)\n    df[\"text\"] = parts[0]\n    df[\"label\"] = parts[1]\n    df = df.dropna(subset=[\"label\"])\n    return df[[\"text\", \"label\"]]\n\ntrain = clean_split(train)\ndev   = clean_split(dev)\ntest  = clean_split(test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:20:26.058363Z","iopub.execute_input":"2026-01-04T13:20:26.058662Z","iopub.status.idle":"2026-01-04T13:20:26.096495Z","shell.execute_reply.started":"2026-01-04T13:20:26.058631Z","shell.execute_reply":"2026-01-04T13:20:26.095705Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:20:26.097564Z","iopub.execute_input":"2026-01-04T13:20:26.097920Z","iopub.status.idle":"2026-01-04T13:20:26.117403Z","shell.execute_reply.started":"2026-01-04T13:20:26.097882Z","shell.execute_reply":"2026-01-04T13:20:26.116748Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text            label\n0  @arya s nair may be athile karthikayude charct...  Non_hope_speech\n1  വാങ്ങിയത് എന്ത് കുന്തം ആയാലും കളയാൻ പറ്റില്ലല്...  Non_hope_speech\n2  മാറുമറയ്ക്കാൻ നടത്തിയ സമരം ഒരു previlege issue...      Hope_speech\n3  ഇഷാനെ കൂടുതല് കെട്ടിപിടിക്കേണ്ട ഞങ്ങൾക്കറിയാം ...  Non_hope_speech\n4  ഇന്ത്യ ഇസ്‌ലാമിക രാജ്യമല്ല.. ഇന്ത്യൻ ഭരണഘടന മാ...      Hope_speech","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@arya s nair may be athile karthikayude charct...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>വാങ്ങിയത് എന്ത് കുന്തം ആയാലും കളയാൻ പറ്റില്ലല്...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>മാറുമറയ്ക്കാൻ നടത്തിയ സമരം ഒരു previlege issue...</td>\n      <td>Hope_speech</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ഇഷാനെ കൂടുതല് കെട്ടിപിടിക്കേണ്ട ഞങ്ങൾക്കറിയാം ...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ഇന്ത്യ ഇസ്‌ലാമിക രാജ്യമല്ല.. ഇന്ത്യൻ ഭരണഘടന മാ...</td>\n      <td>Hope_speech</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import re\ndef filter_not_malayalam(df):\n    return df[~df[\"text\"].str.contains(\"not-malayalam\", case=False, na=False)]\n\ntrain = filter_not_malayalam(train)\ndev   = filter_not_malayalam(dev)\ntest  = filter_not_malayalam(test)\n\ndef clean_text_ml(t):\n    t = re.sub(r\"@\\w+\", \"\", t)   # remove @mentions\n    t = re.sub(r\"http\\S+|www\\S+\", \"\", t)\n    t = re.sub(r\"\\s+\", \" \", t).strip()\n    return t\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:20:26.118517Z","iopub.execute_input":"2026-01-04T13:20:26.118870Z","iopub.status.idle":"2026-01-04T13:20:26.138989Z","shell.execute_reply.started":"2026-01-04T13:20:26.118824Z","shell.execute_reply":"2026-01-04T13:20:26.138142Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# train = preprocess_malayalam(train)\n# dev   = preprocess_malayalam(dev)\n# test  = preprocess_malayalam(test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:20:26.140699Z","iopub.execute_input":"2026-01-04T13:20:26.140959Z","iopub.status.idle":"2026-01-04T13:20:26.152392Z","shell.execute_reply.started":"2026-01-04T13:20:26.140929Z","shell.execute_reply":"2026-01-04T13:20:26.151731Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:20:26.153124Z","iopub.execute_input":"2026-01-04T13:20:26.153805Z","iopub.status.idle":"2026-01-04T13:20:26.171289Z","shell.execute_reply.started":"2026-01-04T13:20:26.153779Z","shell.execute_reply":"2026-01-04T13:20:26.170688Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                   text            label\n0     @arya s nair may be athile karthikayude charct...  Non_hope_speech\n1     വാങ്ങിയത് എന്ത് കുന്തം ആയാലും കളയാൻ പറ്റില്ലല്...  Non_hope_speech\n2     മാറുമറയ്ക്കാൻ നടത്തിയ സമരം ഒരു previlege issue...      Hope_speech\n3     ഇഷാനെ കൂടുതല് കെട്ടിപിടിക്കേണ്ട ഞങ്ങൾക്കറിയാം ...  Non_hope_speech\n4     ഇന്ത്യ ഇസ്‌ലാമിക രാജ്യമല്ല.. ഇന്ത്യൻ ഭരണഘടന മാ...      Hope_speech\n...                                                 ...              ...\n8559            Evan eatha eee pottan oru vivaravumilla  Non_hope_speech\n8560  Ithinu pakaramayi upayogikkan pattunna Indian ...  Non_hope_speech\n8561                               സാറിന് നല്ലത് വരട്ടെ  Non_hope_speech\n8562  ഇങ്ങനത്തെ നല്ല നല്ല അറിവുകൾ പറഞ്ഞു തരുന്ന ഈ ഡോ...      Hope_speech\n8563  Happy wedding Anniverserygod bless you. കരയെല്...      Hope_speech\n\n[8564 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@arya s nair may be athile karthikayude charct...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>വാങ്ങിയത് എന്ത് കുന്തം ആയാലും കളയാൻ പറ്റില്ലല്...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>മാറുമറയ്ക്കാൻ നടത്തിയ സമരം ഒരു previlege issue...</td>\n      <td>Hope_speech</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ഇഷാനെ കൂടുതല് കെട്ടിപിടിക്കേണ്ട ഞങ്ങൾക്കറിയാം ...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ഇന്ത്യ ഇസ്‌ലാമിക രാജ്യമല്ല.. ഇന്ത്യൻ ഭരണഘടന മാ...</td>\n      <td>Hope_speech</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8559</th>\n      <td>Evan eatha eee pottan oru vivaravumilla</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>8560</th>\n      <td>Ithinu pakaramayi upayogikkan pattunna Indian ...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>8561</th>\n      <td>സാറിന് നല്ലത് വരട്ടെ</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>8562</th>\n      <td>ഇങ്ങനത്തെ നല്ല നല്ല അറിവുകൾ പറഞ്ഞു തരുന്ന ഈ ഡോ...</td>\n      <td>Hope_speech</td>\n    </tr>\n    <tr>\n      <th>8563</th>\n      <td>Happy wedding Anniverserygod bless you. കരയെല്...</td>\n      <td>Hope_speech</td>\n    </tr>\n  </tbody>\n</table>\n<p>8564 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"train[\"text\"] = train[\"text\"].apply(clean_text_ml)\ndev[\"text\"]   = dev[\"text\"].apply(clean_text_ml)\ntest[\"text\"]  = test[\"text\"].apply(clean_text_ml)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:21:49.923952Z","iopub.execute_input":"2026-01-04T13:21:49.924755Z","iopub.status.idle":"2026-01-04T13:21:50.015461Z","shell.execute_reply.started":"2026-01-04T13:21:49.924726Z","shell.execute_reply":"2026-01-04T13:21:50.014903Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"label_map = {\n    \"Hope_speech\": 1,\n    \"Non_hope_speech\": 0\n}\n\ntrain[\"label\"] = train[\"label\"].map(label_map)\ndev[\"label\"]   = dev[\"label\"].map(label_map)\ntest[\"label\"]  = test[\"label\"].map(label_map)\n\ntrain = train.dropna()\ndev   = dev.dropna()\ntest  = test.dropna()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:22:02.001992Z","iopub.execute_input":"2026-01-04T13:22:02.002808Z","iopub.status.idle":"2026-01-04T13:22:02.014764Z","shell.execute_reply.started":"2026-01-04T13:22:02.002775Z","shell.execute_reply":"2026-01-04T13:22:02.014033Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:22:21.492872Z","iopub.execute_input":"2026-01-04T13:22:21.493182Z","iopub.status.idle":"2026-01-04T13:22:21.502037Z","shell.execute_reply.started":"2026-01-04T13:22:21.493157Z","shell.execute_reply":"2026-01-04T13:22:21.501282Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                                   text  label\n0     s nair may be athile karthikayude charctr bise...    0.0\n1     വാങ്ങിയത് എന്ത് കുന്തം ആയാലും കളയാൻ പറ്റില്ലല്...    0.0\n2     മാറുമറയ്ക്കാൻ നടത്തിയ സമരം ഒരു previlege issue...    1.0\n3     ഇഷാനെ കൂടുതല് കെട്ടിപിടിക്കേണ്ട ഞങ്ങൾക്കറിയാം ...    0.0\n4     ഇന്ത്യ ഇസ്‌ലാമിക രാജ്യമല്ല.. ഇന്ത്യൻ ഭരണഘടന മാ...    1.0\n...                                                 ...    ...\n8559            Evan eatha eee pottan oru vivaravumilla    0.0\n8560  Ithinu pakaramayi upayogikkan pattunna Indian ...    0.0\n8561                               സാറിന് നല്ലത് വരട്ടെ    0.0\n8562  ഇങ്ങനത്തെ നല്ല നല്ല അറിവുകൾ പറഞ്ഞു തരുന്ന ഈ ഡോ...    1.0\n8563  Happy wedding Anniverserygod bless you. കരയെല്...    1.0\n\n[7869 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>s nair may be athile karthikayude charctr bise...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>വാങ്ങിയത് എന്ത് കുന്തം ആയാലും കളയാൻ പറ്റില്ലല്...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>മാറുമറയ്ക്കാൻ നടത്തിയ സമരം ഒരു previlege issue...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ഇഷാനെ കൂടുതല് കെട്ടിപിടിക്കേണ്ട ഞങ്ങൾക്കറിയാം ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ഇന്ത്യ ഇസ്‌ലാമിക രാജ്യമല്ല.. ഇന്ത്യൻ ഭരണഘടന മാ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8559</th>\n      <td>Evan eatha eee pottan oru vivaravumilla</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8560</th>\n      <td>Ithinu pakaramayi upayogikkan pattunna Indian ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8561</th>\n      <td>സാറിന് നല്ലത് വരട്ടെ</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8562</th>\n      <td>ഇങ്ങനത്തെ നല്ല നല്ല അറിവുകൾ പറഞ്ഞു തരുന്ന ഈ ഡോ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8563</th>\n      <td>Happy wedding Anniverserygod bless you. കരയെല്...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7869 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# 1. Imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# 2. Device definition  ✅ REQUIRED\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# 3. Load embedding models\nmpnet_model = SentenceTransformer(\n    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n    device=device\n)\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:31:36.405672Z","iopub.execute_input":"2026-01-04T13:31:36.406010Z","iopub.status.idle":"2026-01-04T13:31:43.027752Z","shell.execute_reply.started":"2026-01-04T13:31:36.405981Z","shell.execute_reply":"2026-01-04T13:31:43.027127Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18d6ef55b4564647b206ee97a5ce9c8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f724f82e1a64d71aa20f40afcc4ee23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd1f762c47741668a36fd24ad784773"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bf0217dec2146818ba541594ae9a08e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aea7428ac71b43b2b1bcb6f6d0088252"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f12fb223e5c14887ba1fa944a9ae12bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9fc6a48e3914814a7a38f8029a0e448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9949a99fcefd402899855a7643ab1e24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7320f309f6744987b7195b080b701915"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d578a49814a45bd9430f2da33f7ad37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a525b57353c54034a615443269ef9b5a"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_texts = train[\"text\"].tolist()\ndev_texts   = dev[\"text\"].tolist()\ntest_texts  = test[\"text\"].tolist()\n\ntrain_mpnet = mpnet_model.encode(train_texts, batch_size=32, show_progress_bar=True)\ndev_mpnet   = mpnet_model.encode(dev_texts, batch_size=32)\ntest_mpnet  = mpnet_model.encode(test_texts, batch_size=32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:34:02.634108Z","iopub.execute_input":"2026-01-04T13:34:02.634721Z","iopub.status.idle":"2026-01-04T13:34:20.774439Z","shell.execute_reply.started":"2026-01-04T13:34:02.634688Z","shell.execute_reply":"2026-01-04T13:34:20.773801Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/246 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c294303b7724a46957b8e42c79752f6"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nimport torch.nn.functional as F\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nindic_model_path = \"/kaggle/input/indic-bert/indic-bert\"  # UPDATE THIS PATH\n\nindic_tokenizer = AutoTokenizer.from_pretrained(indic_model_path)\nindic_model = AutoModel.from_pretrained(indic_model_path).to(device)\n\nindic_model.eval()\nprint(\"IndicBERT loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:39:42.786875Z","iopub.execute_input":"2026-01-04T13:39:42.787287Z","iopub.status.idle":"2026-01-04T13:39:46.237785Z","shell.execute_reply.started":"2026-01-04T13:39:42.787256Z","shell.execute_reply":"2026-01-04T13:39:46.237120Z"}},"outputs":[{"name":"stdout","text":"IndicBERT loaded\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output.last_hidden_state\n    mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * mask, dim=1) / torch.clamp(mask.sum(dim=1), min=1e-9)\ndef extract_indicbert_embeddings(texts, batch_size=32):\n    all_embeddings = []\n\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n\n        encoded = indic_tokenizer(\n            batch_texts,\n            padding=True,\n            truncation=True,\n            max_length=128,\n            return_tensors=\"pt\"\n        )\n\n        encoded = {k: v.to(device) for k, v in encoded.items()}\n\n        with torch.no_grad():\n            output = indic_model(**encoded)\n\n        embeddings = mean_pooling(output, encoded[\"attention_mask\"])\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n\n        all_embeddings.append(embeddings.cpu())\n\n    return torch.cat(all_embeddings).numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:40:13.737931Z","iopub.execute_input":"2026-01-04T13:40:13.738512Z","iopub.status.idle":"2026-01-04T13:40:13.744909Z","shell.execute_reply.started":"2026-01-04T13:40:13.738477Z","shell.execute_reply":"2026-01-04T13:40:13.744359Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_indic_emb = extract_indicbert_embeddings(train_texts)\ndev_indic_emb   = extract_indicbert_embeddings(dev_texts)\ntest_indic_emb  = extract_indicbert_embeddings(test_texts)\n\nprint(train_indic_emb.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:40:33.169274Z","iopub.execute_input":"2026-01-04T13:40:33.169867Z","iopub.status.idle":"2026-01-04T13:41:36.004538Z","shell.execute_reply.started":"2026-01-04T13:40:33.169835Z","shell.execute_reply":"2026-01-04T13:41:36.003713Z"}},"outputs":[{"name":"stdout","text":"(7869, 768)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"#CNN(AGNOSTIC)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass HopeSpeechCNN(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.dropout = nn.Dropout(0.25)\n\n        self.conv1 = nn.Conv1d(1, 64, kernel_size=5)\n        self.pool1 = nn.MaxPool1d(4)\n\n        self.conv2 = nn.Conv1d(64, 64, kernel_size=5)\n        self.pool2 = nn.MaxPool1d(4)\n\n        self.conv3 = nn.Conv1d(64, 64, kernel_size=5)\n        self.pool3 = nn.MaxPool1d(4)\n\n        # Dynamically compute output size\n        self._dummy_forward(input_dim)\n\n        self.fc_out = nn.Linear(self.flatten_dim, 2)\n\n    def _dummy_forward(self, input_dim):\n        with torch.no_grad():\n            x = torch.zeros(1, input_dim)\n            x = x.unsqueeze(1)\n            x = self.pool1(F.relu(self.conv1(x)))\n            x = self.pool2(F.relu(self.conv2(x)))\n            x = self.pool3(F.relu(self.conv3(x)))\n            self.flatten_dim = x.numel()\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n\n        x = x.unsqueeze(1)\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n\n        x = x.view(x.size(0), -1)\n        return self.fc_out(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:44:41.579163Z","iopub.execute_input":"2026-01-04T13:44:41.580042Z","iopub.status.idle":"2026-01-04T13:44:41.588133Z","shell.execute_reply.started":"2026-01-04T13:44:41.580005Z","shell.execute_reply":"2026-01-04T13:44:41.587372Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\nimport torch.optim as optim\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef evaluate(model, loader,device):\n    model.eval()\n    preds, labels = [], []\n\n    with torch.no_grad():\n        for X, y in loader:\n            X, y = X.to(device), y.to(device)\n            logits = model(X)\n            pred = torch.argmax(logits, dim=1)\n\n            preds.extend(pred.cpu().numpy())\n            labels.extend(y.cpu().numpy())\n\n    acc = accuracy_score(labels, preds)\n    macro_f1 = f1_score(labels, preds, average=\"macro\")\n    return acc, macro_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:45:04.381948Z","iopub.execute_input":"2026-01-04T13:45:04.382750Z","iopub.status.idle":"2026-01-04T13:45:04.388914Z","shell.execute_reply.started":"2026-01-04T13:45:04.382707Z","shell.execute_reply":"2026-01-04T13:45:04.388006Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def train_model(\n    model,\n    train_loader,\n    dev_loader,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"model\",\n    device=\"cuda\"\n):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    best_f1 = 0.0\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        for X, y in train_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            optimizer.zero_grad()\n            logits = model(X)\n            loss = criterion(logits, y)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n\n        dev_acc, dev_f1 = evaluate(model, dev_loader, device)\n\n        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n        print(f\"Train Loss: {avg_loss:.4f}\")\n        print(f\"Dev Acc   : {dev_acc:.4f}\")\n        print(f\"Dev F1    : {dev_f1:.4f}\")\n\n        if dev_f1 > best_f1:\n            best_f1 = dev_f1\n            torch.save(model.state_dict(), f\"{model_name}.pt\")\n            print(\" Best model saved\")\n\n    print(f\"\\n Best Dev Macro-F1 ({model_name}): {best_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:47:35.521185Z","iopub.execute_input":"2026-01-04T13:47:35.521529Z","iopub.status.idle":"2026-01-04T13:47:35.528884Z","shell.execute_reply.started":"2026-01-04T13:47:35.521502Z","shell.execute_reply":"2026-01-04T13:47:35.528203Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\n\ndef make_loaders(train_emb, dev_emb, test_emb, y_train, y_dev, y_test, batch_size=32):\n\n    train_ds = TensorDataset(\n        torch.tensor(train_emb, dtype=torch.float32),\n        torch.tensor(y_train, dtype=torch.long)\n    )\n\n    dev_ds = TensorDataset(\n        torch.tensor(dev_emb, dtype=torch.float32),\n        torch.tensor(y_dev, dtype=torch.long)\n    )\n\n    test_ds = TensorDataset(\n        torch.tensor(test_emb, dtype=torch.float32),\n        torch.tensor(y_test, dtype=torch.long)\n    )\n\n    return (\n        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n        DataLoader(dev_ds, batch_size=batch_size),\n        DataLoader(test_ds, batch_size=batch_size)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:47:55.805415Z","iopub.execute_input":"2026-01-04T13:47:55.805726Z","iopub.status.idle":"2026-01-04T13:47:55.812267Z","shell.execute_reply.started":"2026-01-04T13:47:55.805691Z","shell.execute_reply":"2026-01-04T13:47:55.811390Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"#mpnet-cnn\ntrain_loader_mpnet, dev_loader_mpnet, test_loader_mpnet = make_loaders(\n    train_mpnet, dev_mpnet, test_mpnet,\n    train[\"label\"], dev[\"label\"], test[\"label\"]\n)\n\nmodel_mpnet = HopeSpeechCNN(input_dim=768).to(device)\n\ntrain_model(\n    model_mpnet,\n    train_loader_mpnet,\n    dev_loader_mpnet,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_mpnet_ml\",\n    device=device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:48:41.479646Z","iopub.execute_input":"2026-01-04T13:48:41.480265Z","iopub.status.idle":"2026-01-04T13:48:49.612010Z","shell.execute_reply.started":"2026-01-04T13:48:41.480234Z","shell.execute_reply":"2026-01-04T13:48:49.611141Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.5089\nDev Acc   : 0.8047\nDev F1    : 0.4459\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.4084\nDev Acc   : 0.8201\nDev F1    : 0.7178\n Best model saved\n\nEpoch 3/10\nTrain Loss: 0.3658\nDev Acc   : 0.8541\nDev F1    : 0.7358\n Best model saved\n\nEpoch 4/10\nTrain Loss: 0.3433\nDev Acc   : 0.8613\nDev F1    : 0.7456\n Best model saved\n\nEpoch 5/10\nTrain Loss: 0.3213\nDev Acc   : 0.8551\nDev F1    : 0.7434\n\nEpoch 6/10\nTrain Loss: 0.3021\nDev Acc   : 0.8438\nDev F1    : 0.7590\n Best model saved\n\nEpoch 7/10\nTrain Loss: 0.2782\nDev Acc   : 0.8479\nDev F1    : 0.7618\n Best model saved\n\nEpoch 8/10\nTrain Loss: 0.2551\nDev Acc   : 0.7811\nDev F1    : 0.7188\n\nEpoch 9/10\nTrain Loss: 0.2298\nDev Acc   : 0.8417\nDev F1    : 0.7540\n\nEpoch 10/10\nTrain Loss: 0.2072\nDev Acc   : 0.7544\nDev F1    : 0.6898\n\n Best Dev Macro-F1 (cnn_mpnet_ml): 0.7618\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"#indicbert-cnn\ntrain_loader_indic, dev_loader_indic, test_loader_indic = make_loaders(\n    train_indic_emb, dev_indic_emb, test_indic_emb,\n    train[\"label\"], dev[\"label\"], test[\"label\"]\n)\n\nmodel_indic = HopeSpeechCNN(input_dim=768).to(device)\n\ntrain_model(\n    model_indic,\n    train_loader_indic,\n    dev_loader_indic,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_indicbert\",\n    device=device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:50:40.731365Z","iopub.execute_input":"2026-01-04T13:50:40.731741Z","iopub.status.idle":"2026-01-04T13:50:48.150516Z","shell.execute_reply.started":"2026-01-04T13:50:40.731707Z","shell.execute_reply":"2026-01-04T13:50:48.149862Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.5390\nDev Acc   : 0.8047\nDev F1    : 0.4459\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.5025\nDev Acc   : 0.8047\nDev F1    : 0.4459\n\nEpoch 3/10\nTrain Loss: 0.4781\nDev Acc   : 0.8047\nDev F1    : 0.4459\n\nEpoch 4/10\nTrain Loss: 0.4514\nDev Acc   : 0.8047\nDev F1    : 0.4459\n\nEpoch 5/10\nTrain Loss: 0.4314\nDev Acc   : 0.8037\nDev F1    : 0.6573\n Best model saved\n\nEpoch 6/10\nTrain Loss: 0.4201\nDev Acc   : 0.7657\nDev F1    : 0.6673\n Best model saved\n\nEpoch 7/10\nTrain Loss: 0.4089\nDev Acc   : 0.7174\nDev F1    : 0.6430\n\nEpoch 8/10\nTrain Loss: 0.4026\nDev Acc   : 0.7986\nDev F1    : 0.6927\n Best model saved\n\nEpoch 9/10\nTrain Loss: 0.3967\nDev Acc   : 0.8068\nDev F1    : 0.6962\n Best model saved\n\nEpoch 10/10\nTrain Loss: 0.3941\nDev Acc   : 0.7564\nDev F1    : 0.6718\n\n Best Dev Macro-F1 (cnn_indicbert): 0.6962\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"X_train_fused = np.concatenate([train_mpnet, train_indic_emb], axis=1)\nX_dev_fused   = np.concatenate([dev_mpnet, dev_indic_emb], axis=1)\nX_test_fused  = np.concatenate([test_mpnet, test_indic_emb], axis=1)\n\nprint(X_train_fused.shape)  # (N, 1536)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:51:25.678348Z","iopub.execute_input":"2026-01-04T13:51:25.678983Z","iopub.status.idle":"2026-01-04T13:51:25.705533Z","shell.execute_reply.started":"2026-01-04T13:51:25.678954Z","shell.execute_reply":"2026-01-04T13:51:25.704884Z"}},"outputs":[{"name":"stdout","text":"(7869, 1536)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"model_fusion = HopeSpeechCNN(input_dim=1536).to(device)\n\ntrain_loader_fus, dev_loader_fus, test_loader_fus = make_loaders(\n    X_train_fused,\n    X_dev_fused,\n    X_test_fused,\n    train[\"label\"], dev[\"label\"], test[\"label\"]\n)\n\ntrain_model(\n    model_fusion,\n    train_loader_fus,\n    dev_loader_fus,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_fusion_ml\",\n    device=device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:51:47.634976Z","iopub.execute_input":"2026-01-04T13:51:47.635265Z","iopub.status.idle":"2026-01-04T13:51:58.071020Z","shell.execute_reply.started":"2026-01-04T13:51:47.635241Z","shell.execute_reply":"2026-01-04T13:51:58.070431Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.5083\nDev Acc   : 0.8047\nDev F1    : 0.4459\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.3990\nDev Acc   : 0.8510\nDev F1    : 0.7020\n Best model saved\n\nEpoch 3/10\nTrain Loss: 0.3625\nDev Acc   : 0.8582\nDev F1    : 0.7266\n Best model saved\n\nEpoch 4/10\nTrain Loss: 0.3422\nDev Acc   : 0.8356\nDev F1    : 0.7363\n Best model saved\n\nEpoch 5/10\nTrain Loss: 0.3222\nDev Acc   : 0.8530\nDev F1    : 0.7515\n Best model saved\n\nEpoch 6/10\nTrain Loss: 0.3040\nDev Acc   : 0.8150\nDev F1    : 0.7422\n\nEpoch 7/10\nTrain Loss: 0.2840\nDev Acc   : 0.8263\nDev F1    : 0.7530\n Best model saved\n\nEpoch 8/10\nTrain Loss: 0.2651\nDev Acc   : 0.8099\nDev F1    : 0.7371\n\nEpoch 9/10\nTrain Loss: 0.2374\nDev Acc   : 0.8510\nDev F1    : 0.7534\n Best model saved\n\nEpoch 10/10\nTrain Loss: 0.2160\nDev Acc   : 0.7595\nDev F1    : 0.6980\n\n Best Dev Macro-F1 (cnn_fusion_ml): 0.7534\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n    classification_report\n)\nimport torch\nimport numpy as np\n\ndef evaluate_on_test(model, test_loader, device):\n    model.eval()\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for x, y in test_loader:\n            x = x.to(device)\n            y = y.to(device)\n\n            logits = model(x)\n            preds = torch.argmax(logits, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y.cpu().numpy())\n\n    acc = accuracy_score(all_labels, all_preds)\n    f1  = f1_score(all_labels, all_preds, average=\"macro\")\n    prec = precision_score(all_labels, all_preds, average=\"macro\")\n    rec  = recall_score(all_labels, all_preds, average=\"macro\")\n\n    print(\"Accuracy      :\", round(acc, 4))\n    print(\"Macro-F1      :\", round(f1, 4))\n    print(\"Macro-Precision:\", round(prec, 4))\n    print(\"Macro-Recall  :\", round(rec, 4))\n    print(\"\\nClassification Report:\\n\")\n    print(classification_report(all_labels, all_preds, digits=4))\n\n    return acc, f1, prec, rec\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:54:53.762826Z","iopub.execute_input":"2026-01-04T13:54:53.763163Z","iopub.status.idle":"2026-01-04T13:54:53.770369Z","shell.execute_reply.started":"2026-01-04T13:54:53.763134Z","shell.execute_reply":"2026-01-04T13:54:53.769785Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MPNet TEST EVALUATION\n\nmodel_mpnet = HopeSpeechCNN(input_dim=768).to(device)\nmodel_mpnet.load_state_dict(torch.load(\"cnn_mpnet_ml.pt\"))\nmodel_mpnet.to(device)\n\nevaluate_on_test(model_mpnet, test_loader_mpnet, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:55:15.973420Z","iopub.execute_input":"2026-01-04T13:55:15.974197Z","iopub.status.idle":"2026-01-04T13:55:16.063474Z","shell.execute_reply.started":"2026-01-04T13:55:15.974166Z","shell.execute_reply":"2026-01-04T13:55:16.062879Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.8741\nMacro-F1      : 0.8064\nMacro-Precision: 0.8009\nMacro-Recall  : 0.8124\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.9269    0.9149    0.9209       776\n           1     0.6749    0.7098    0.6919       193\n\n    accuracy                         0.8741       969\n   macro avg     0.8009    0.8124    0.8064       969\nweighted avg     0.8767    0.8741    0.8753       969\n\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(0.8740970072239422,\n 0.8064005816924105,\n 0.8008848988411426,\n 0.8123965065968698)"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# INDICBERT TEST EVALUATION\n\nmodel_indic = HopeSpeechCNN(input_dim=768).to(device)\nmodel_indic.load_state_dict(torch.load(\"cnn_indicbert.pt\"))\nmodel_indic.to(device)\n\nevaluate_on_test(model_indic, test_loader_indic, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:57:56.492144Z","iopub.execute_input":"2026-01-04T13:57:56.492451Z","iopub.status.idle":"2026-01-04T13:57:56.569475Z","shell.execute_reply.started":"2026-01-04T13:57:56.492422Z","shell.execute_reply":"2026-01-04T13:57:56.568782Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.8204\nMacro-F1      : 0.7163\nMacro-Precision: 0.7181\nMacro-Recall  : 0.7147\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.8859    0.8905    0.8882       776\n           1     0.5503    0.5389    0.5445       193\n\n    accuracy                         0.8204       969\n   macro avg     0.7181    0.7147    0.7163       969\nweighted avg     0.8190    0.8204    0.8197       969\n\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(0.8204334365325078, 0.7163387124994953, 0.718080993080993, 0.7146620105763581)"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# FUSION TEST EVALUATION\nmodel_fusion = HopeSpeechCNN(input_dim=768*2).to(device)\nmodel_fusion.load_state_dict(torch.load(\"cnn_fusion_ml.pt\"))\n\nevaluate_on_test(model_fusion, test_loader_fus, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T13:59:09.381043Z","iopub.execute_input":"2026-01-04T13:59:09.381594Z","iopub.status.idle":"2026-01-04T13:59:09.485774Z","shell.execute_reply.started":"2026-01-04T13:59:09.381567Z","shell.execute_reply":"2026-01-04T13:59:09.485242Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.8648\nMacro-F1      : 0.7825\nMacro-Precision: 0.7905\nMacro-Recall  : 0.7755\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.9087    0.9240    0.9163       776\n           1     0.6722    0.6269    0.6488       193\n\n    accuracy                         0.8648       969\n   macro avg     0.7905    0.7755    0.7825       969\nweighted avg     0.8616    0.8648    0.8630       969\n\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(0.8648090815273478, 0.782543747698053, 0.7904837346852556, 0.7754560386731478)"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"results = {}\ndef evaluate_and_store(name, model, dev_loader, test_loader, device):\n    from sklearn.metrics import f1_score\n    import torch\n\n    def eval_loader(loader):\n        model.eval()\n        preds, labels = [], []\n\n        with torch.no_grad():\n            for x, y in loader:\n                x = x.to(device)\n                y = y.to(device)\n\n                logits = model(x)\n                preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n                labels.extend(y.cpu().numpy())\n\n        return f1_score(labels, preds, average=\"macro\")\n\n    dev_f1  = eval_loader(dev_loader)\n    test_f1 = eval_loader(test_loader)\n\n    results[name] = {\n        \"Dev Macro-F1\": round(dev_f1, 4),\n        \"Test Macro-F1\": round(test_f1, 4)\n    }\n\n    print(name)\n    print(\" Dev Macro-F1 :\", round(dev_f1, 4))\n    print(\" Test Macro-F1:\", round(test_f1, 4))\n    print(\"-\" * 40)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:02:09.048737Z","iopub.execute_input":"2026-01-04T14:02:09.049258Z","iopub.status.idle":"2026-01-04T14:02:09.055406Z","shell.execute_reply.started":"2026-01-04T14:02:09.049226Z","shell.execute_reply":"2026-01-04T14:02:09.054653Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"model_mpnet = HopeSpeechCNN(input_dim=768).to(device)\nmodel_mpnet.load_state_dict(torch.load(\"cnn_mpnet_ml.pt\"))\n\nevaluate_and_store(\n    \"MPNet-CNN\",\n    model_mpnet,\n    dev_loader_mpnet,\n    test_loader_mpnet,\n    device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:02:27.280885Z","iopub.execute_input":"2026-01-04T14:02:27.281694Z","iopub.status.idle":"2026-01-04T14:02:27.386799Z","shell.execute_reply.started":"2026-01-04T14:02:27.281660Z","shell.execute_reply":"2026-01-04T14:02:27.386242Z"}},"outputs":[{"name":"stdout","text":"MPNet-CNN\n Dev Macro-F1 : 0.7618\n Test Macro-F1: 0.8064\n----------------------------------------\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"model_indic = HopeSpeechCNN(input_dim=768).to(device)\nmodel_indic.load_state_dict(torch.load(\"cnn_indicbert.pt\"))\n\nevaluate_and_store(\n    \"IndicBERT-CNN\",\n    model_indic,\n    dev_loader_indic,\n    test_loader_indic,\n    device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:02:40.863661Z","iopub.execute_input":"2026-01-04T14:02:40.864354Z","iopub.status.idle":"2026-01-04T14:02:40.971845Z","shell.execute_reply.started":"2026-01-04T14:02:40.864324Z","shell.execute_reply":"2026-01-04T14:02:40.971231Z"}},"outputs":[{"name":"stdout","text":"IndicBERT-CNN\n Dev Macro-F1 : 0.6962\n Test Macro-F1: 0.7163\n----------------------------------------\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"model_indic = HopeSpeechCNN(input_dim=768*2).to(device)\nmodel_indic.load_state_dict(torch.load(\"/kaggle/working/cnn_fusion_ml.pt\"))\n\nevaluate_and_store(\n    \"FUSION-CNN\",\n    model_fusion,\n    dev_loader_fus,\n    test_loader_fus,\n    device\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:03:52.431548Z","iopub.execute_input":"2026-01-04T14:03:52.432121Z","iopub.status.idle":"2026-01-04T14:03:52.574189Z","shell.execute_reply.started":"2026-01-04T14:03:52.432078Z","shell.execute_reply":"2026-01-04T14:03:52.573376Z"}},"outputs":[{"name":"stdout","text":"FUSION-CNN\n Dev Macro-F1 : 0.7534\n Test Macro-F1: 0.7825\n----------------------------------------\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"import pandas as pd\n\ndf_results = pd.DataFrame(results).T\ndf_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:04:17.344283Z","iopub.execute_input":"2026-01-04T14:04:17.344577Z","iopub.status.idle":"2026-01-04T14:04:17.353876Z","shell.execute_reply.started":"2026-01-04T14:04:17.344550Z","shell.execute_reply":"2026-01-04T14:04:17.353319Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"               Dev Macro-F1  Test Macro-F1\nMPNet-CNN            0.7618         0.8064\nIndicBERT-CNN        0.6962         0.7163\nFUSION-CNN           0.7534         0.7825","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dev Macro-F1</th>\n      <th>Test Macro-F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MPNet-CNN</th>\n      <td>0.7618</td>\n      <td>0.8064</td>\n    </tr>\n    <tr>\n      <th>IndicBERT-CNN</th>\n      <td>0.6962</td>\n      <td>0.7163</td>\n    </tr>\n    <tr>\n      <th>FUSION-CNN</th>\n      <td>0.7534</td>\n      <td>0.7825</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":50}]}