{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13955263,"sourceType":"datasetVersion","datasetId":8895175}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:55:25.145869Z","iopub.execute_input":"2025-12-26T17:55:25.146093Z","iopub.status.idle":"2025-12-26T17:55:27.137460Z","shell.execute_reply.started":"2025-12-26T17:55:25.146071Z","shell.execute_reply":"2025-12-26T17:55:27.136691Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hope-english/english_hope_dev.csv\n/kaggle/input/hope-english/english_hope_test.csv\n/kaggle/input/hope-english/english_hope_train.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv(\"/kaggle/input/hope-english/english_hope_train.csv\", sep=\"\\t\", header=None)\ndev   = pd.read_csv(\"/kaggle/input/hope-english/english_hope_dev.csv\", sep=\"\\t\", header=None)\ntest  = pd.read_csv(\"/kaggle/input/hope-english/english_hope_test.csv\", sep=\"\\t\", header=None)\n\ntrain.columns = [\"raw\"]\ndev.columns = [\"raw\"]\ntest.columns = [\"raw\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:55:27.139209Z","iopub.execute_input":"2025-12-26T17:55:27.139663Z","iopub.status.idle":"2025-12-26T17:55:27.285230Z","shell.execute_reply.started":"2025-12-26T17:55:27.139630Z","shell.execute_reply":"2025-12-26T17:55:27.284438Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def clean_split(df):\n    df = df.copy()\n\n    # split by \";\" into max 3 parts\n    parts = df[\"raw\"].str.split(\";\", expand=True)\n    \n    # parts[0] = text  \n    # parts[1] = label\n    df[\"text\"] = parts[0]\n    df[\"label\"] = parts[1]\n\n    # drop rows without labels\n    df = df.dropna(subset=[\"label\"])\n    \n    # keep only text + label\n    df = df[[\"text\", \"label\"]]\n    return df\n\ntrain = clean_split(train)\ndev = clean_split(dev)\ntest = clean_split(test)\n\nprint(train.head())\nprint(train.shape)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:55:27.286889Z","iopub.execute_input":"2025-12-26T17:55:27.287197Z","iopub.status.idle":"2025-12-26T17:55:27.428490Z","shell.execute_reply.started":"2025-12-26T17:55:27.287166Z","shell.execute_reply":"2025-12-26T17:55:27.427667Z"}},"outputs":[{"name":"stdout","text":"                                                text            label\n0  these tiktoks radiate gay chaotic energy and i...  Non_hope_speech\n1  @Champions Again He got killed for using false...  Non_hope_speech\n2               It's not that all lives don't matter  Non_hope_speech\n3  Is it really that difficult to understand? Bla...  Non_hope_speech\n4  Whenever we say black isn't that racists?  Why...  Non_hope_speech\n(22762, 2)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import re\n\ndef clean_text(t):\n    t = t.lower()\n    t = re.sub(r\"http\\S+|www\\S+\", \"\", t)       # remove URLs\n    t = re.sub(r\"@\\w+\", \"\", t)                # remove usernames\n    t = re.sub(r\"\\s+\", \" \", t).strip()        # remove extra spaces\n    return t\n\ntrain[\"text\"] = train[\"text\"].apply(clean_text)\ndev[\"text\"] = dev[\"text\"].apply(clean_text)\ntest[\"text\"] = test[\"text\"].apply(clean_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:55:27.429546Z","iopub.execute_input":"2025-12-26T17:55:27.429886Z","iopub.status.idle":"2025-12-26T17:55:27.712713Z","shell.execute_reply.started":"2025-12-26T17:55:27.429854Z","shell.execute_reply":"2025-12-26T17:55:27.712016Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"label_map = {\n    \"Hope_speech\": 1,\n    \"Non_hope_speech\": 0\n}\n\ntrain[\"label\"] = train[\"label\"].map(label_map)\ndev[\"label\"]   = dev[\"label\"].map(label_map)\ntest[\"label\"]  = test[\"label\"].map(label_map)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:55:27.714743Z","iopub.execute_input":"2025-12-26T17:55:27.715012Z","iopub.status.idle":"2025-12-26T17:55:27.726920Z","shell.execute_reply.started":"2025-12-26T17:55:27.714989Z","shell.execute_reply":"2025-12-26T17:55:27.725974Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train = train.dropna(subset=[\"label\"])\ndev   = dev.dropna(subset=[\"label\"])\ntest  = test.dropna(subset=[\"label\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:55:27.728026Z","iopub.execute_input":"2025-12-26T17:55:27.728359Z","iopub.status.idle":"2025-12-26T17:55:27.748706Z","shell.execute_reply.started":"2025-12-26T17:55:27.728327Z","shell.execute_reply":"2025-12-26T17:55:27.748032Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(train[\"label\"].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:55:27.749732Z","iopub.execute_input":"2025-12-26T17:55:27.750039Z","iopub.status.idle":"2025-12-26T17:55:27.768405Z","shell.execute_reply.started":"2025-12-26T17:55:27.750010Z","shell.execute_reply":"2025-12-26T17:55:27.767659Z"}},"outputs":[{"name":"stdout","text":"label\n0.0    20700\n1.0     1945\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\nimport torch.nn.functional as F\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:55:27.770045Z","iopub.execute_input":"2025-12-26T17:55:27.770276Z","iopub.status.idle":"2025-12-26T17:56:14.457515Z","shell.execute_reply.started":"2025-12-26T17:55:27.770257Z","shell.execute_reply":"2025-12-26T17:56:14.456675Z"}},"outputs":[{"name":"stderr","text":"2025-12-26 17:55:50.354588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766771750.823621      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766771750.936778      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766771752.038130      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766771752.038170      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766771752.038173      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766771752.038176      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"mpnet_model = SentenceTransformer(\n    \"sentence-transformers/all-mpnet-base-v2\",\n    device=device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:56:14.458567Z","iopub.execute_input":"2025-12-26T17:56:14.459168Z","iopub.status.idle":"2025-12-26T17:56:19.648037Z","shell.execute_reply.started":"2025-12-26T17:56:14.459139Z","shell.execute_reply":"2025-12-26T17:56:19.647355Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ae782aab0a421fa4a3ecf4f51e400e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4faebdfbd7df4ed2b095638ad4992b79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cd80f3ca692477a88f81221951d8df3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45f04125f85a41979f972d9ae97a249f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6421392c21674cd0b4a08cc1748c2665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c43d6f1c5c947708fa6d616e0202d5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a15fc3288a14df196ab016b06ad45b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ae6fde647de47a9b082799e3bd38a6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb3ffb63496e4c57b325164387f63a60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"121b2558b5844d97b6453c3fa566bba5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7569f2f5330943228d5208235c56cfc2"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"t5_model = SentenceTransformer(\n    \"sentence-transformers/sentence-t5-base\",\n    device=device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:56:19.648962Z","iopub.execute_input":"2025-12-26T17:56:19.649229Z","iopub.status.idle":"2025-12-26T17:56:24.455019Z","shell.execute_reply.started":"2025-12-26T17:56:19.649205Z","shell.execute_reply":"2025-12-26T17:56:24.454181Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b892cc93c364e438fb582b6484039d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17d26b63ecea43368b14cef6c129baf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3dc43874b8247c2a3136aaaaae4d2bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb7afbc8667b4f4b86426707f485cdfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3e84dbb93d04351a71da5904ede495c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/219M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5396a5ca09f44e9dadb91dcecd911e3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ea2dea6f0b74f48a3ee326ee5fcb8d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a19ca60123114f8385337180bb2b0070"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cd13fee0c9d48d68b85e3fb4a8026dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75cefd3ffc714494b11e7ff4a7eae788"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a6e80d7939f40308d7476cd04cd1738"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8becf967a8c42b3a75a3264505b8dd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"2_Dense/model.safetensors:   0%|          | 0.00/2.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6d29a93ec884ac489a76c44264dd810"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"roberta_name = \"roberta-base\"\nroberta_tokenizer = AutoTokenizer.from_pretrained(roberta_name)\nroberta_model = AutoModel.from_pretrained(roberta_name).to(device)\nroberta_model.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:56:24.456038Z","iopub.execute_input":"2025-12-26T17:56:24.456376Z","iopub.status.idle":"2025-12-26T17:56:28.091369Z","shell.execute_reply.started":"2025-12-26T17:56:24.456350Z","shell.execute_reply":"2025-12-26T17:56:28.090582Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"752740e63a9c4c7e8b0464fa887e0afa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4be2909f46934292914607e68dde3a98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab0e470e26414a14b0855890070ee127"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ab599492c2436fa47cf8ef6024a407"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99e3c2d4189146e8851026ed1718d90c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eee180797bd46e2a9cd2a4c336aee6e"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"RobertaModel(\n  (embeddings): RobertaEmbeddings(\n    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n    (position_embeddings): Embedding(514, 768, padding_idx=1)\n    (token_type_embeddings): Embedding(1, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): RobertaEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): RobertaPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def encode_roberta(texts, batch_size=32):\n    all_embeddings = []\n\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i+batch_size]\n\n        encoded = roberta_tokenizer(\n            batch,\n            padding=True,\n            truncation=True,\n            max_length=128,\n            return_tensors=\"pt\"\n        ).to(device)\n\n        with torch.no_grad():\n            output = roberta_model(**encoded)\n\n        # CLS token\n        cls_emb = output.last_hidden_state[:, 0, :]\n        cls_emb = F.normalize(cls_emb, p=2, dim=1)\n\n        all_embeddings.append(cls_emb.cpu())\n\n    return torch.cat(all_embeddings).numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:56:28.092369Z","iopub.execute_input":"2025-12-26T17:56:28.092701Z","iopub.status.idle":"2025-12-26T17:56:28.098317Z","shell.execute_reply.started":"2025-12-26T17:56:28.092665Z","shell.execute_reply":"2025-12-26T17:56:28.097728Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_texts = train[\"text\"].tolist()\ndev_texts   = dev[\"text\"].tolist()\ntest_texts  = test[\"text\"].tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:56:28.099276Z","iopub.execute_input":"2025-12-26T17:56:28.099584Z","iopub.status.idle":"2025-12-26T17:56:28.177720Z","shell.execute_reply.started":"2025-12-26T17:56:28.099549Z","shell.execute_reply":"2025-12-26T17:56:28.176995Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#MPNet\ntrain_mpnet = mpnet_model.encode(train_texts, batch_size=32, show_progress_bar=True)\ndev_mpnet   = mpnet_model.encode(dev_texts, batch_size=32)\ntest_mpnet  = mpnet_model.encode(test_texts, batch_size=32)\n\n#T5 \ntrain_t5 = t5_model.encode(train_texts, batch_size=32, show_progress_bar=True)\ndev_t5   = t5_model.encode(dev_texts, batch_size=32)\ntest_t5  = t5_model.encode(test_texts, batch_size=32)\n\n#Roberta CLS\ntrain_rob = encode_roberta(train_texts)\ndev_rob   = encode_roberta(dev_texts)\ntest_rob  = encode_roberta(test_texts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T17:56:28.180866Z","iopub.execute_input":"2025-12-26T17:56:28.181112Z","iopub.status.idle":"2025-12-26T18:00:12.600743Z","shell.execute_reply.started":"2025-12-26T17:56:28.181089Z","shell.execute_reply":"2025-12-26T18:00:12.600097Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/708 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b9bf135372d4ce1a1dbd23e5ce2373a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/708 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"372a0044687742d5be8e67b23b56a684"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"#CNN(AGNOSTIC)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass HopeSpeechCNN(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.dropout = nn.Dropout(0.25)\n\n        self.conv1 = nn.Conv1d(1, 64, kernel_size=5)\n        self.pool1 = nn.MaxPool1d(4)\n\n        self.conv2 = nn.Conv1d(64, 64, kernel_size=5)\n        self.pool2 = nn.MaxPool1d(4)\n\n        self.conv3 = nn.Conv1d(64, 64, kernel_size=5)\n        self.pool3 = nn.MaxPool1d(4)\n\n        # Dynamically compute output size\n        self._dummy_forward(input_dim)\n\n        self.fc_out = nn.Linear(self.flatten_dim, 2)\n\n    def _dummy_forward(self, input_dim):\n        with torch.no_grad():\n            x = torch.zeros(1, input_dim)\n            x = x.unsqueeze(1)\n            x = self.pool1(F.relu(self.conv1(x)))\n            x = self.pool2(F.relu(self.conv2(x)))\n            x = self.pool3(F.relu(self.conv3(x)))\n            self.flatten_dim = x.numel()\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n\n        x = x.unsqueeze(1)\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n\n        x = x.view(x.size(0), -1)\n        return self.fc_out(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:00:12.601770Z","iopub.execute_input":"2025-12-26T18:00:12.602078Z","iopub.status.idle":"2025-12-26T18:00:12.610251Z","shell.execute_reply.started":"2025-12-26T18:00:12.602044Z","shell.execute_reply":"2025-12-26T18:00:12.609621Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\nimport torch.optim as optim\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef evaluate(model, loader,device):\n    model.eval()\n    preds, labels = [], []\n\n    with torch.no_grad():\n        for X, y in loader:\n            X, y = X.to(device), y.to(device)\n            logits = model(X)\n            pred = torch.argmax(logits, dim=1)\n\n            preds.extend(pred.cpu().numpy())\n            labels.extend(y.cpu().numpy())\n\n    acc = accuracy_score(labels, preds)\n    macro_f1 = f1_score(labels, preds, average=\"macro\")\n    return acc, macro_f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:01:02.337391Z","iopub.execute_input":"2025-12-26T18:01:02.337720Z","iopub.status.idle":"2025-12-26T18:01:02.344149Z","shell.execute_reply.started":"2025-12-26T18:01:02.337690Z","shell.execute_reply":"2025-12-26T18:01:02.343393Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# def train_model(model, train_loader, dev_loader, epochs=10, lr=1e-4):\n#     model.to(device)\n#     criterion = nn.CrossEntropyLoss()\n#     optimizer = optim.Adam(model.parameters(), lr=lr)\n\n#     best_f1 = 0.0\n\n#     for epoch in range(epochs):\n#         model.train()\n#         total_loss = 0\n\n#         for X, y in train_loader:\n#             X, y = X.to(device), y.to(device)\n\n#             optimizer.zero_grad()\n#             logits = model(X)\n#             loss = criterion(logits, y)\n#             loss.backward()\n#             optimizer.step()\n\n#             total_loss += loss.item()\n\n#         acc, f1 = evaluate(model, dev_loader)\n\n#         print(f\"\\nEpoch {epoch+1}/{epochs}\")\n#         print(f\"Train Loss: {total_loss/len(train_loader):.4f}\")\n#         print(f\"Dev Acc   : {acc:.4f}\")\n#         print(f\"Dev F1    : {f1:.4f}\")\n\n#         if f1 > best_f1:\n#             best_f1 = f1\n#             torch.save(model.state_dict(), \"best_model.pt\")\n#             print(\" Best model saved\")\n\n#     print(f\"\\nBest Dev Macro-F1: {best_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:00:12.633768Z","iopub.execute_input":"2025-12-26T18:00:12.634061Z","iopub.status.idle":"2025-12-26T18:00:12.654332Z","shell.execute_reply.started":"2025-12-26T18:00:12.634036Z","shell.execute_reply":"2025-12-26T18:00:12.653805Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train_model(\n    model,\n    train_loader,\n    dev_loader,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"model\",\n    device=\"cuda\"\n):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    best_f1 = 0.0\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        for X, y in train_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            optimizer.zero_grad()\n            logits = model(X)\n            loss = criterion(logits, y)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n\n        dev_acc, dev_f1 = evaluate(model, dev_loader, device)\n\n        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n        print(f\"Train Loss: {avg_loss:.4f}\")\n        print(f\"Dev Acc   : {dev_acc:.4f}\")\n        print(f\"Dev F1    : {dev_f1:.4f}\")\n\n        if dev_f1 > best_f1:\n            best_f1 = dev_f1\n            torch.save(model.state_dict(), f\"{model_name}.pt\")\n            print(\" Best model saved\")\n\n    print(f\"\\n Best Dev Macro-F1 ({model_name}): {best_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:00:12.655033Z","iopub.execute_input":"2025-12-26T18:00:12.655285Z","iopub.status.idle":"2025-12-26T18:00:12.672260Z","shell.execute_reply.started":"2025-12-26T18:00:12.655253Z","shell.execute_reply":"2025-12-26T18:00:12.671736Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\n\ndef make_loaders(train_emb, dev_emb, test_emb, y_train, y_dev, y_test, batch_size=32):\n\n    train_ds = TensorDataset(\n        torch.tensor(train_emb, dtype=torch.float32),\n        torch.tensor(y_train, dtype=torch.long)\n    )\n\n    dev_ds = TensorDataset(\n        torch.tensor(dev_emb, dtype=torch.float32),\n        torch.tensor(y_dev, dtype=torch.long)\n    )\n\n    test_ds = TensorDataset(\n        torch.tensor(test_emb, dtype=torch.float32),\n        torch.tensor(y_test, dtype=torch.long)\n    )\n\n    return (\n        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n        DataLoader(dev_ds, batch_size=batch_size),\n        DataLoader(test_ds, batch_size=batch_size)\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:00:12.673095Z","iopub.execute_input":"2025-12-26T18:00:12.673388Z","iopub.status.idle":"2025-12-26T18:00:12.698519Z","shell.execute_reply.started":"2025-12-26T18:00:12.673356Z","shell.execute_reply":"2025-12-26T18:00:12.697994Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_loader_mpnet, dev_loader_mpnet, test_loader_mpnet = make_loaders(\n    train_mpnet, dev_mpnet, test_mpnet,\n    train[\"label\"], dev[\"label\"], test[\"label\"]\n)\n\nmodel_mpnet = HopeSpeechCNN(input_dim=768).to(device)\n\ntrain_model(\n    model_mpnet,\n    train_loader_mpnet,\n    dev_loader_mpnet,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_mpnet\",\n    device=device\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:01:08.770461Z","iopub.execute_input":"2025-12-26T18:01:08.771190Z","iopub.status.idle":"2025-12-26T18:01:30.614468Z","shell.execute_reply.started":"2025-12-26T18:01:08.771156Z","shell.execute_reply":"2025-12-26T18:01:30.613643Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.2687\nDev Acc   : 0.9039\nDev F1    : 0.4748\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.1829\nDev Acc   : 0.9247\nDev F1    : 0.7465\n Best model saved\n\nEpoch 3/10\nTrain Loss: 0.1687\nDev Acc   : 0.9216\nDev F1    : 0.7705\n Best model saved\n\nEpoch 4/10\nTrain Loss: 0.1580\nDev Acc   : 0.9208\nDev F1    : 0.7707\n Best model saved\n\nEpoch 5/10\nTrain Loss: 0.1482\nDev Acc   : 0.9127\nDev F1    : 0.7734\n Best model saved\n\nEpoch 6/10\nTrain Loss: 0.1356\nDev Acc   : 0.9254\nDev F1    : 0.7785\n Best model saved\n\nEpoch 7/10\nTrain Loss: 0.1228\nDev Acc   : 0.9251\nDev F1    : 0.7801\n Best model saved\n\nEpoch 8/10\nTrain Loss: 0.1104\nDev Acc   : 0.9131\nDev F1    : 0.7707\n\nEpoch 9/10\nTrain Loss: 0.0959\nDev Acc   : 0.9205\nDev F1    : 0.7802\n Best model saved\n\nEpoch 10/10\nTrain Loss: 0.0821\nDev Acc   : 0.7887\nDev F1    : 0.6612\n\n Best Dev Macro-F1 (cnn_mpnet): 0.7802\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# #MPNET TRAINING\n# train_loader, dev_loader, test_loader = make_loaders(\n#     train_mpnet, dev_mpnet, test_mpnet,\n#     train[\"label\"], dev[\"label\"], test[\"label\"]\n# )\n\n# model = HopeSpeechCNN(input_dim=768)\n# train_model(model, train_loader, dev_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:00:16.163528Z","iopub.status.idle":"2025-12-26T18:00:16.163822Z","shell.execute_reply.started":"2025-12-26T18:00:16.163669Z","shell.execute_reply":"2025-12-26T18:00:16.163685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# T5 TRAINING\n\nmodel_t5 = HopeSpeechCNN(input_dim=768).to(device)\n\ntrain_loader_t5, dev_loader_t5, test_loader_t5 = make_loaders(\n    train_t5, dev_t5, test_t5,\n    train[\"label\"], dev[\"label\"], test[\"label\"]\n)\n\ntrain_model(\n    model_t5,\n    train_loader_t5,\n    dev_loader_t5,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_t5\",\n    device=device\n)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:05:28.481855Z","iopub.execute_input":"2025-12-26T18:05:28.482216Z","iopub.status.idle":"2025-12-26T18:05:49.321575Z","shell.execute_reply.started":"2025-12-26T18:05:28.482187Z","shell.execute_reply":"2025-12-26T18:05:49.320853Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.2889\nDev Acc   : 0.9039\nDev F1    : 0.4748\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.1887\nDev Acc   : 0.8993\nDev F1    : 0.7639\n Best model saved\n\nEpoch 3/10\nTrain Loss: 0.1797\nDev Acc   : 0.8823\nDev F1    : 0.7483\n\nEpoch 4/10\nTrain Loss: 0.1769\nDev Acc   : 0.8940\nDev F1    : 0.7624\n\nEpoch 5/10\nTrain Loss: 0.1747\nDev Acc   : 0.8862\nDev F1    : 0.7569\n\nEpoch 6/10\nTrain Loss: 0.1732\nDev Acc   : 0.8816\nDev F1    : 0.7528\n\nEpoch 7/10\nTrain Loss: 0.1713\nDev Acc   : 0.8477\nDev F1    : 0.7176\n\nEpoch 8/10\nTrain Loss: 0.1690\nDev Acc   : 0.9078\nDev F1    : 0.7788\n Best model saved\n\nEpoch 9/10\nTrain Loss: 0.1683\nDev Acc   : 0.7936\nDev F1    : 0.6654\n\nEpoch 10/10\nTrain Loss: 0.1669\nDev Acc   : 0.7898\nDev F1    : 0.6631\n\n Best Dev Macro-F1 (cnn_t5): 0.7788\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# model_rob = HopeSpeechCNN(input_dim=768).to(device)\n\n# train_loader, dev_loader, test_loader = make_loaders(\n#     train_rob, dev_rob, test_rob,\n#     train[\"label\"], dev[\"label\"], test[\"label\"]\n# )\n\n# train_model(model_rob, train_loader, dev_loader)\n\n# ROBERTA TRAINING\n\nmodel_rob = HopeSpeechCNN(input_dim=768).to(device)\n\ntrain_loader_rob, dev_loader_rob, test_loader_rob = make_loaders(\n    train_rob, dev_rob, test_rob,\n    train[\"label\"], dev[\"label\"], test[\"label\"]\n)\n\ntrain_model(\n    model_rob,\n    train_loader_rob,\n    dev_loader_rob,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_roberta\",\n    device=device\n)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:08:36.154330Z","iopub.execute_input":"2025-12-26T18:08:36.154666Z","iopub.status.idle":"2025-12-26T18:08:56.787677Z","shell.execute_reply.started":"2025-12-26T18:08:36.154638Z","shell.execute_reply":"2025-12-26T18:08:56.787097Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.3183\nDev Acc   : 0.9039\nDev F1    : 0.4748\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.2872\nDev Acc   : 0.9039\nDev F1    : 0.4748\n\nEpoch 3/10\nTrain Loss: 0.2704\nDev Acc   : 0.9039\nDev F1    : 0.4748\n\nEpoch 4/10\nTrain Loss: 0.2375\nDev Acc   : 0.9042\nDev F1    : 0.6825\n Best model saved\n\nEpoch 5/10\nTrain Loss: 0.2144\nDev Acc   : 0.8883\nDev F1    : 0.7114\n Best model saved\n\nEpoch 6/10\nTrain Loss: 0.2088\nDev Acc   : 0.8767\nDev F1    : 0.7226\n Best model saved\n\nEpoch 7/10\nTrain Loss: 0.2058\nDev Acc   : 0.8488\nDev F1    : 0.6997\n\nEpoch 8/10\nTrain Loss: 0.2028\nDev Acc   : 0.8883\nDev F1    : 0.7325\n Best model saved\n\nEpoch 9/10\nTrain Loss: 0.2019\nDev Acc   : 0.8933\nDev F1    : 0.7376\n Best model saved\n\nEpoch 10/10\nTrain Loss: 0.2006\nDev Acc   : 0.9028\nDev F1    : 0.7455\n Best model saved\n\n Best Dev Macro-F1 (cnn_roberta): 0.7455\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import numpy as np\n\n# Fusion: MPNet + T5 + RoBERTa\nX_train_fused = np.concatenate([train_mpnet, train_t5, train_rob], axis=1)\nX_dev_fused   = np.concatenate([dev_mpnet, dev_t5, dev_rob], axis=1)\nX_test_fused  = np.concatenate([test_mpnet, test_t5, test_rob], axis=1)\n\nprint(X_train_fused.shape)  # (N, 2304)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:11:41.808966Z","iopub.execute_input":"2025-12-26T18:11:41.809546Z","iopub.status.idle":"2025-12-26T18:11:41.910068Z","shell.execute_reply.started":"2025-12-26T18:11:41.809515Z","shell.execute_reply":"2025-12-26T18:11:41.909437Z"}},"outputs":[{"name":"stdout","text":"(22645, 2304)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# FUSION TRAINING\n\ninput_dim = X_train_fused.shape[1]  # 2304\n\nmodel_fusion = HopeSpeechCNN(input_dim=input_dim).to(device)\n\ntrain_loader_fus, dev_loader_fus, test_loader_fus = make_loaders(\n    X_train_fused,\n    X_dev_fused,\n    X_test_fused,\n    train[\"label\"],\n    dev[\"label\"],\n    test[\"label\"]\n)\n\ntrain_model(\n    model_fusion,\n    train_loader_fus,\n    dev_loader_fus,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_fusion\",\n    device=device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:12:24.979226Z","iopub.execute_input":"2025-12-26T18:12:24.979977Z","iopub.status.idle":"2025-12-26T18:13:09.566766Z","shell.execute_reply.started":"2025-12-26T18:12:24.979943Z","shell.execute_reply":"2025-12-26T18:13:09.566118Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.2387\nDev Acc   : 0.9265\nDev F1    : 0.7668\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.1730\nDev Acc   : 0.9283\nDev F1    : 0.7622\n\nEpoch 3/10\nTrain Loss: 0.1660\nDev Acc   : 0.9297\nDev F1    : 0.7748\n Best model saved\n\nEpoch 4/10\nTrain Loss: 0.1601\nDev Acc   : 0.9318\nDev F1    : 0.7765\n Best model saved\n\nEpoch 5/10\nTrain Loss: 0.1564\nDev Acc   : 0.9251\nDev F1    : 0.7958\n Best model saved\n\nEpoch 6/10\nTrain Loss: 0.1496\nDev Acc   : 0.9304\nDev F1    : 0.7980\n Best model saved\n\nEpoch 7/10\nTrain Loss: 0.1449\nDev Acc   : 0.9318\nDev F1    : 0.7939\n\nEpoch 8/10\nTrain Loss: 0.1380\nDev Acc   : 0.8908\nDev F1    : 0.7567\n\nEpoch 9/10\nTrain Loss: 0.1322\nDev Acc   : 0.8958\nDev F1    : 0.7644\n\nEpoch 10/10\nTrain Loss: 0.1252\nDev Acc   : 0.9032\nDev F1    : 0.7675\n\n Best Dev Macro-F1 (cnn_fusion): 0.7980\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_loader, dev_loader, test_loader = make_loaders(\n#     X_train_fused,\n#     X_dev_fused,\n#     X_test_fused,\n#     train[\"label\"],\n#     dev[\"label\"],\n#     test[\"label\"]\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:00:16.168838Z","iopub.status.idle":"2025-12-26T18:00:16.169134Z","shell.execute_reply.started":"2025-12-26T18:00:16.169010Z","shell.execute_reply":"2025-12-26T18:00:16.169030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# input_dim = X_train_fused.shape[1]\n\n# model_fusion = HopeSpeechCNN(input_dim=input_dim).to(device)\n\n# train_model(\n#     model_fusion,\n#     train_loader,\n#     dev_loader,\n#     epochs=10,\n#     lr=1e-4\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:00:16.170219Z","iopub.status.idle":"2025-12-26T18:00:16.170590Z","shell.execute_reply.started":"2025-12-26T18:00:16.170384Z","shell.execute_reply":"2025-12-26T18:00:16.170425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n    classification_report\n)\nimport torch\nimport numpy as np\n\ndef evaluate_on_test(model, test_loader, device):\n    model.eval()\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for x, y in test_loader:\n            x = x.to(device)\n            y = y.to(device)\n\n            logits = model(x)\n            preds = torch.argmax(logits, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y.cpu().numpy())\n\n    acc = accuracy_score(all_labels, all_preds)\n    f1  = f1_score(all_labels, all_preds, average=\"macro\")\n    prec = precision_score(all_labels, all_preds, average=\"macro\")\n    rec  = recall_score(all_labels, all_preds, average=\"macro\")\n\n    print(\"Accuracy      :\", round(acc, 4))\n    print(\"Macro-F1      :\", round(f1, 4))\n    print(\"Macro-Precision:\", round(prec, 4))\n    print(\"Macro-Recall  :\", round(rec, 4))\n    print(\"\\nClassification Report:\\n\")\n    print(classification_report(all_labels, all_preds, digits=4))\n\n    return acc, f1, prec, rec\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:19:11.903209Z","iopub.execute_input":"2025-12-26T18:19:11.903535Z","iopub.status.idle":"2025-12-26T18:19:11.911031Z","shell.execute_reply.started":"2025-12-26T18:19:11.903508Z","shell.execute_reply":"2025-12-26T18:19:11.910425Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# MPNet TEST EVALUATION\n\nmodel_mpnet = HopeSpeechCNN(input_dim=768).to(device)\nmodel_mpnet.load_state_dict(torch.load(\"cnn_mpnet.pt\"))\nmodel_mpnet.to(device)\n\nevaluate_on_test(model_mpnet, test_loader_mpnet, device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:20:07.109476Z","iopub.execute_input":"2025-12-26T18:20:07.110255Z","iopub.status.idle":"2025-12-26T18:20:07.322534Z","shell.execute_reply.started":"2025-12-26T18:20:07.110223Z","shell.execute_reply":"2025-12-26T18:20:07.321939Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.9233\nMacro-F1      : 0.7818\nMacro-Precision: 0.7588\nMacro-Recall  : 0.8115\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.9683    0.9469    0.9575      2581\n           1     0.5493    0.6761    0.6062       247\n\n    accuracy                         0.9233      2828\n   macro avg     0.7588    0.8115    0.7818      2828\nweighted avg     0.9317    0.9233    0.9268      2828\n\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(0.9232673267326733,\n 0.7818316265857999,\n 0.7588231920927517,\n 0.8115165794257946)"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# T5 TEST EVALUATION\n\nmodel_t5 = HopeSpeechCNN(input_dim=768).to(device)\nmodel_t5.load_state_dict(torch.load(\"cnn_t5.pt\"))\nmodel_t5.to(device)\n\nevaluate_on_test(model_t5, test_loader_t5, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:21:01.695277Z","iopub.execute_input":"2025-12-26T18:21:01.696111Z","iopub.status.idle":"2025-12-26T18:21:01.857123Z","shell.execute_reply.started":"2025-12-26T18:21:01.696078Z","shell.execute_reply":"2025-12-26T18:21:01.856421Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.9028\nMacro-F1      : 0.7619\nMacro-Precision: 0.7208\nMacro-Recall  : 0.8406\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.9761    0.9159    0.9450      2581\n           1     0.4655    0.7652    0.5789       247\n\n    accuracy                         0.9028      2828\n   macro avg     0.7208    0.8406    0.7619      2828\nweighted avg     0.9315    0.9028    0.9131      2828\n\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"(0.9027581329561527, 0.761949874485722, 0.7207850451322646, 0.8405531233382535)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# ROBERTA TEST EVALUATION\n\nmodel_rob = HopeSpeechCNN(input_dim=768).to(device)\nmodel_rob.load_state_dict(torch.load(\"cnn_roberta.pt\"))\nmodel_rob.to(device)\n\nevaluate_on_test(model_rob, test_loader_rob, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:21:38.227117Z","iopub.execute_input":"2025-12-26T18:21:38.227623Z","iopub.status.idle":"2025-12-26T18:21:38.382663Z","shell.execute_reply.started":"2025-12-26T18:21:38.227594Z","shell.execute_reply":"2025-12-26T18:21:38.381940Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.9098\nMacro-F1      : 0.7436\nMacro-Precision: 0.7238\nMacro-Recall  : 0.7694\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.9608    0.9396    0.9500      2581\n           1     0.4868    0.5992    0.5372       247\n\n    accuracy                         0.9098      2828\n   macro avg     0.7238    0.7694    0.7436      2828\nweighted avg     0.9194    0.9098    0.9140      2828\n\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(0.9098302687411598, 0.7436270266330828, 0.7238093252147803, 0.769374297066542)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"# FUSION TEST EVALUATION\n\ninput_dim = X_test_fused.shape[1]\n\nmodel_fusion = HopeSpeechCNN(input_dim=input_dim).to(device)\nmodel_fusion.load_state_dict(torch.load(\"cnn_fusion.pt\"))\nmodel_fusion.to(device)\n\nevaluate_on_test(model_fusion, test_loader_fus, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:22:09.044294Z","iopub.execute_input":"2025-12-26T18:22:09.044906Z","iopub.status.idle":"2025-12-26T18:22:09.325377Z","shell.execute_reply.started":"2025-12-26T18:22:09.044862Z","shell.execute_reply":"2025-12-26T18:22:09.324578Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.9318\nMacro-F1      : 0.7856\nMacro-Precision: 0.7861\nMacro-Recall  : 0.785\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.9624    0.9628    0.9626      2581\n           1     0.6098    0.6073    0.6085       247\n\n    accuracy                         0.9318      2828\n   macro avg     0.7861    0.7850    0.7856      2828\nweighted avg     0.9316    0.9318    0.9317      2828\n\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(0.9317538896746818,\n 0.7855689511774174,\n 0.7860941603219285,\n 0.7850462818447483)"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"results = {}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:38:01.598642Z","iopub.execute_input":"2025-12-26T18:38:01.599088Z","iopub.status.idle":"2025-12-26T18:38:01.603053Z","shell.execute_reply.started":"2025-12-26T18:38:01.599057Z","shell.execute_reply":"2025-12-26T18:38:01.602302Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def evaluate_and_store(name, model, dev_loader, test_loader, device):\n    from sklearn.metrics import f1_score\n    import torch\n\n    def eval_loader(loader):\n        model.eval()\n        preds, labels = [], []\n\n        with torch.no_grad():\n            for x, y in loader:\n                x, y = x.to(device), y.to(device)\n                logits = model(x)\n                preds.extend(torch.argmax(logits, 1).cpu().numpy())\n                labels.extend(y.cpu().numpy())\n\n        return f1_score(labels, preds, average=\"macro\")\n\n    dev_f1 = eval_loader(dev_loader)\n    test_f1 = eval_loader(test_loader)\n\n    results[name] = {\n        \"Dev Macro-F1\": round(dev_f1, 4),\n        \"Test Macro-F1\": round(test_f1, 4)\n    }\n\n    print(f\"{name}\")\n    print(\" Dev Macro-F1 :\", round(dev_f1, 4))\n    print(\" Test Macro-F1:\", round(test_f1, 4))\n    print(\"-\" * 40)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:38:14.460032Z","iopub.execute_input":"2025-12-26T18:38:14.460739Z","iopub.status.idle":"2025-12-26T18:38:14.466368Z","shell.execute_reply.started":"2025-12-26T18:38:14.460706Z","shell.execute_reply":"2025-12-26T18:38:14.465833Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"model_mpnet = HopeSpeechCNN(input_dim=768).to(device)\nmodel_mpnet.load_state_dict(torch.load(\"cnn_mpnet.pt\"))\n\nevaluate_and_store(\n    \"MPNet-CNN\",\n    model_mpnet,\n    dev_loader_mpnet,\n    test_loader_mpnet,\n    device\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:39:07.728396Z","iopub.execute_input":"2025-12-26T18:39:07.729101Z","iopub.status.idle":"2025-12-26T18:39:07.984127Z","shell.execute_reply.started":"2025-12-26T18:39:07.729071Z","shell.execute_reply":"2025-12-26T18:39:07.983470Z"}},"outputs":[{"name":"stdout","text":"MPNet-CNN\n Dev Macro-F1 : 0.7802\n Test Macro-F1: 0.7818\n----------------------------------------\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"#t5\nmodel_t5 = HopeSpeechCNN(input_dim=768).to(device)\nmodel_t5.load_state_dict(torch.load(\"cnn_t5.pt\"))\n\nevaluate_and_store(\n    \"Sentence-T5-CNN\",\n    model_t5,\n    dev_loader_t5,\n    test_loader_t5,\n    device\n)\n\n#roberta\nmodel_rob = HopeSpeechCNN(input_dim=768).to(device)\nmodel_rob.load_state_dict(torch.load(\"cnn_roberta.pt\"))\n\nevaluate_and_store(\n    \"RoBERTa-CNN\",\n    model_rob,\n    dev_loader_rob,\n    test_loader_rob,\n    device\n)\n\n#fusion\ninput_dim = X_test_fused.shape[1]\n\nmodel_fusion = HopeSpeechCNN(input_dim=input_dim).to(device)\nmodel_fusion.load_state_dict(torch.load(\"cnn_fusion.pt\"))\n\nevaluate_and_store(\n    \"Fusion-CNN (MPNet+T5+RoBERTa)\",\n    model_fusion,\n    dev_loader_fus,\n    test_loader_fus,\n    device\n)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:40:51.732468Z","iopub.execute_input":"2025-12-26T18:40:51.732946Z","iopub.status.idle":"2025-12-26T18:40:52.624098Z","shell.execute_reply.started":"2025-12-26T18:40:51.732916Z","shell.execute_reply":"2025-12-26T18:40:52.623297Z"}},"outputs":[{"name":"stdout","text":"Sentence-T5-CNN\n Dev Macro-F1 : 0.7788\n Test Macro-F1: 0.7619\n----------------------------------------\nRoBERTa-CNN\n Dev Macro-F1 : 0.7455\n Test Macro-F1: 0.7436\n----------------------------------------\nFusion-CNN (MPNet+T5+RoBERTa)\n Dev Macro-F1 : 0.798\n Test Macro-F1: 0.7856\n----------------------------------------\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import pandas as pd\n\ndf_results = pd.DataFrame(results).T\ndf_results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T18:41:08.731200Z","iopub.execute_input":"2025-12-26T18:41:08.731769Z","iopub.status.idle":"2025-12-26T18:41:08.751134Z","shell.execute_reply.started":"2025-12-26T18:41:08.731725Z","shell.execute_reply":"2025-12-26T18:41:08.750373Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                               Dev Macro-F1  Test Macro-F1\nMPNet-CNN                            0.7802         0.7818\nSentence-T5-CNN                      0.7788         0.7619\nRoBERTa-CNN                          0.7455         0.7436\nFusion-CNN (MPNet+T5+RoBERTa)        0.7980         0.7856","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dev Macro-F1</th>\n      <th>Test Macro-F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MPNet-CNN</th>\n      <td>0.7802</td>\n      <td>0.7818</td>\n    </tr>\n    <tr>\n      <th>Sentence-T5-CNN</th>\n      <td>0.7788</td>\n      <td>0.7619</td>\n    </tr>\n    <tr>\n      <th>RoBERTa-CNN</th>\n      <td>0.7455</td>\n      <td>0.7436</td>\n    </tr>\n    <tr>\n      <th>Fusion-CNN (MPNet+T5+RoBERTa)</th>\n      <td>0.7980</td>\n      <td>0.7856</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45}]}