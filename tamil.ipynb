{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:32:34.471102Z","iopub.execute_input":"2026-01-04T14:32:34.471278Z","iopub.status.idle":"2026-01-04T14:32:35.675353Z","shell.execute_reply.started":"2026-01-04T14:32:34.471251Z","shell.execute_reply":"2026-01-04T14:32:35.674575Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/indic-bert/indic-bert/config.json\n/kaggle/input/indic-bert/indic-bert/spiece.vocab\n/kaggle/input/indic-bert/indic-bert/spiece.model\n/kaggle/input/indic-bert/indic-bert/README.md\n/kaggle/input/indic-bert/indic-bert/tf_model.ckpt.meta\n/kaggle/input/indic-bert/indic-bert/tf_model.ckpt.data-00000-of-00001\n/kaggle/input/indic-bert/indic-bert/pytorch_model.bin\n/kaggle/input/indic-bert/indic-bert/.gitattributes\n/kaggle/input/indic-bert/indic-bert/tf_model.ckpt.index\n/kaggle/input/indic-bert/indic-bert/.git/config\n/kaggle/input/indic-bert/indic-bert/.git/packed-refs\n/kaggle/input/indic-bert/indic-bert/.git/HEAD\n/kaggle/input/indic-bert/indic-bert/.git/index\n/kaggle/input/indic-bert/indic-bert/.git/description\n/kaggle/input/indic-bert/indic-bert/.git/info/exclude\n/kaggle/input/indic-bert/indic-bert/.git/refs/heads/main\n/kaggle/input/indic-bert/indic-bert/.git/refs/remotes/origin/HEAD\n/kaggle/input/indic-bert/indic-bert/.git/hooks/pre-merge-commit.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/post-merge\n/kaggle/input/indic-bert/indic-bert/.git/hooks/pre-push\n/kaggle/input/indic-bert/indic-bert/.git/hooks/prepare-commit-msg.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/update.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/pre-push.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/pre-rebase.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/pre-applypatch.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/post-commit\n/kaggle/input/indic-bert/indic-bert/.git/hooks/post-checkout\n/kaggle/input/indic-bert/indic-bert/.git/hooks/push-to-checkout.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/pre-commit.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/commit-msg.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/post-update.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/pre-receive.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/fsmonitor-watchman.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/applypatch-msg.sample\n/kaggle/input/indic-bert/indic-bert/.git/hooks/sendemail-validate.sample\n/kaggle/input/indic-bert/indic-bert/.git/lfs/objects/94/c7/94c747585b0126ba2886423f69844e03cb7a4f198f6e15c42afedbccbf80a138\n/kaggle/input/indic-bert/indic-bert/.git/lfs/objects/51/a5/51a52801f044b66e11ce318b2d20463b1ef0a63723cba2228677306bfa65aa8e\n/kaggle/input/indic-bert/indic-bert/.git/logs/HEAD\n/kaggle/input/indic-bert/indic-bert/.git/logs/refs/heads/main\n/kaggle/input/indic-bert/indic-bert/.git/logs/refs/remotes/origin/HEAD\n/kaggle/input/indic-bert/indic-bert/.git/objects/36/c642d3c2050669a60f2cdbc8fe400247abb530\n/kaggle/input/indic-bert/indic-bert/.git/objects/05/430f42a65fa85be049199d2d5db1d82798cad7\n/kaggle/input/indic-bert/indic-bert/.git/objects/64/43b7bab7ad1ab7f8ad404dd5205cf26178f393\n/kaggle/input/indic-bert/indic-bert/.git/objects/9e/7ff913c8da10a150492733459f9799c7b54f7a\n/kaggle/input/indic-bert/indic-bert/.git/objects/89/d0736b7273480d3ee2e5ecbaf70c338e2d4ebb\n/kaggle/input/indic-bert/indic-bert/.git/objects/f0/36a4688c914e5b994d18e5dcb788bd03d020a0\n/kaggle/input/indic-bert/indic-bert/.git/objects/dc/08351d4dc0732d9c8af04070ced089b201ce2f\n/kaggle/input/indic-bert/indic-bert/.git/objects/dc/f097d066260fa89f66bac614ee9c9cb7f0f483\n/kaggle/input/indic-bert/indic-bert/.git/objects/55/d84275004f19c77f9442f4225a7479aca54c2c\n/kaggle/input/indic-bert/indic-bert/.git/objects/be/431f23760c15b845b6033c682cd55d02bea1f3\n/kaggle/input/indic-bert/indic-bert/.git/objects/ea/b93f590a078485db9ef328737a211db48d2825\n/kaggle/input/indic-bert/indic-bert/.git/objects/49/c0ce2dda1d0f6de1dc7f188c73868933f0de3c\n/kaggle/input/indic-bert/indic-bert/.git/objects/e3/2a89f0d0a178bdc94ebc8292ede8f1c9c41c24\n/kaggle/input/indic-bert/indic-bert/.git/objects/f9/e53973a9945c0b1748563a8a849e8bc150626a\n/kaggle/input/indic-bert/indic-bert/.git/objects/d2/0494f1d9c24d8c8e004939abe5af60bb0d9011\n/kaggle/input/indic-bert/indic-bert/.git/objects/66/d87f06ca6c8dced21c230fb7489bc9c07a86e8\n/kaggle/input/indic-bert/indic-bert/.git/objects/13/dc833ab1629772017cada22ce998aa06c4fdc1\n/kaggle/input/indic-bert/indic-bert/.git/objects/71/f57324d22421f15aa563cd7e489ea7bbf92ab3\n/kaggle/input/indic-bert/indic-bert/.git/objects/71/2f843fe03a214b38b75710507139a3c9f597ee\n/kaggle/input/indic-bert/indic-bert/.git/objects/09/3508b00293e0fe847f73f0b9f7b8723a1b13eb\n/kaggle/input/indic-bert/indic-bert/.git/objects/09/d164af42b5b1e1fc0f8fd60c5de394cb340bae\n/kaggle/input/indic-bert/indic-bert/.git/objects/97/ae2d6440dbd1a2698540223dc00b43075c69c9\n/kaggle/input/indic-bert/indic-bert/.git/objects/8e/b24fae01f7ae77b94bbeb15110be75fd33a0b4\n/kaggle/input/indic-bert/indic-bert/.git/objects/a9/32850aac5ce8d79e0371f184f5758cc641d21c\n/kaggle/input/indic-bert/indic-bert/.git/objects/a9/0ff0c70e05aacc62211686590f0d9fdeb6c53c\n/kaggle/input/indic-bert/indic-bert/.git/objects/1f/d532410d547a10a93514bf8288b77ca7683c5a\n/kaggle/input/indic-bert/indic-bert/.git/objects/a1/cf67360f0aa3034e38566ce677bbbe01bb4cad\n/kaggle/input/indic-bert/indic-bert/.git/objects/68/900e5e2003dca4e5800df693a935dfb1bd6bce\n/kaggle/input/indic-bert/indic-bert/.git/objects/4a/d775d93ff49cdc2d8f67be7e0f384e952aab37\n/kaggle/input/indic-bert/indic-bert/.git/objects/fa/5b0851dcf4aa5613cc6df216c6074cf2d21fe1\n/kaggle/input/indic-bert/indic-bert/.git/objects/54/0c50726d60fc903e408f0e54dff8192980c8df\n/kaggle/input/indic-bert/indic-bert/.git/objects/48/42dd258ecc0546f0d660b76a3b22a9c632f401\n/kaggle/input/indic-bert/indic-bert/.git/objects/ee/d801975ae9164d5bfffb56ec0e4c5d8ade787e\n/kaggle/input/indic-bert/indic-bert/.git/objects/29/9a0a02278dce936ab446319ecbab954ef59274\n/kaggle/input/indic-bert/indic-bert/.git/objects/24/9680c66bc132c2f9e9ca0894317547d1075723\n/kaggle/input/indic-bert/indic-bert/dev/null/post-merge\n/kaggle/input/indic-bert/indic-bert/dev/null/pre-push\n/kaggle/input/indic-bert/indic-bert/dev/null/post-commit\n/kaggle/input/indic-bert/indic-bert/dev/null/post-checkout\n/kaggle/input/tamil-dataset/tamil_hope_first_test.csv\n/kaggle/input/tamil-dataset/tamil_hope_first_dev.csv\n/kaggle/input/tamil-dataset/tamil_hope_first_train.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom sentence_transformers import SentenceTransformer\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:32:35.677146Z","iopub.execute_input":"2026-01-04T14:32:35.677693Z","iopub.status.idle":"2026-01-04T14:33:05.582499Z","shell.execute_reply.started":"2026-01-04T14:32:35.677639Z","shell.execute_reply":"2026-01-04T14:33:05.581854Z"}},"outputs":[{"name":"stderr","text":"2026-01-04 14:32:49.477556: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767537169.684864      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767537169.738978      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767537170.245101      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767537170.245139      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767537170.245142      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767537170.245145      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\n# Replace with your Tamil dataset paths\ntrain = pd.read_csv(\"/kaggle/input/tamil-dataset/tamil_hope_first_train.csv\", sep=\"\\t\", header=None)\ndev   = pd.read_csv(\"/kaggle/input/tamil-dataset/tamil_hope_first_dev.csv\", sep=\"\\t\", header=None)\ntest  = pd.read_csv(\"/kaggle/input/tamil-dataset/tamil_hope_first_test.csv\", sep=\"\\t\", header=None)\n\ntrain.columns = [\"raw\"]\ndev.columns = [\"raw\"]\ntest.columns = [\"raw\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:33:05.583294Z","iopub.execute_input":"2026-01-04T14:33:05.583896Z","iopub.status.idle":"2026-01-04T14:33:05.662595Z","shell.execute_reply.started":"2026-01-04T14:33:05.583867Z","shell.execute_reply":"2026-01-04T14:33:05.661959Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def clean_split_tamil(df):\n    df = df.copy()\n    # split by \";\" or whatever separator your dataset uses\n    parts = df[\"raw\"].str.split(\";\", expand=True)\n    \n    df[\"text\"] = parts[0]\n    df[\"label\"] = parts[1]\n\n    # drop rows without labels\n    df = df.dropna(subset=[\"label\"])\n    \n    # remove 'not-Tamil' rows\n    df = df[df[\"label\"] != \"not-Tamil\"]\n\n    # keep only text + label\n    df = df[[\"text\", \"label\"]]\n    return df\n\ntrain = clean_split_tamil(train)\ndev   = clean_split_tamil(dev)\ntest  = clean_split_tamil(test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:33:05.663576Z","iopub.execute_input":"2026-01-04T14:33:05.664301Z","iopub.status.idle":"2026-01-04T14:33:05.719361Z","shell.execute_reply.started":"2026-01-04T14:33:05.664265Z","shell.execute_reply":"2026-01-04T14:33:05.718558Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import re\n\ndef clean_text_tamil(t):\n    t = str(t).lower()\n    t = re.sub(r\"http\\S+|www\\S+\", \"\", t)       # remove URLs\n    t = re.sub(r\"@\\w+\", \"\", t)                 # remove usernames\n    t = re.sub(r\"\\s+\", \" \", t).strip()         # remove extra spaces\n    return t\n\ntrain[\"text\"] = train[\"text\"].apply(clean_text_tamil)\ndev[\"text\"]   = dev[\"text\"].apply(clean_text_tamil)\ntest[\"text\"]  = test[\"text\"].apply(clean_text_tamil)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:33:05.720372Z","iopub.execute_input":"2026-01-04T14:33:05.720596Z","iopub.status.idle":"2026-01-04T14:33:05.842695Z","shell.execute_reply.started":"2026-01-04T14:33:05.720575Z","shell.execute_reply":"2026-01-04T14:33:05.841936Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:33:34.917429Z","iopub.execute_input":"2026-01-04T14:33:34.918170Z","iopub.status.idle":"2026-01-04T14:33:34.938991Z","shell.execute_reply.started":"2026-01-04T14:33:34.918139Z","shell.execute_reply":"2026-01-04T14:33:34.938253Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                    text            label\n1      i also don't have tiktok hello and allnbut i'm...      Hope_speech\n2      thalaivare..neengale inum one plus mobile vach...  Non_hope_speech\n3      annee varanda thondai.. corona virus affect pa...      Hope_speech\n4                                     5views but 18likes  Non_hope_speech\n5      china phone vakathiga inu evanga ellam tiktok ...  Non_hope_speech\n...                                                  ...              ...\n16155                         7pm correcta erukum mg bro      Hope_speech\n16156  intha karutha mudija varaikum neengalum ellark...  Non_hope_speech\n16157  and neenga adhiyavasiyam nu soldra apps like t...  Non_hope_speech\n16158                          daii sekram mater ku vada      Hope_speech\n16159                             bro put redmi 8 gaming      Hope_speech\n\n[14200 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>i also don't have tiktok hello and allnbut i'm...</td>\n      <td>Hope_speech</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thalaivare..neengale inum one plus mobile vach...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>annee varanda thondai.. corona virus affect pa...</td>\n      <td>Hope_speech</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5views but 18likes</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>china phone vakathiga inu evanga ellam tiktok ...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16155</th>\n      <td>7pm correcta erukum mg bro</td>\n      <td>Hope_speech</td>\n    </tr>\n    <tr>\n      <th>16156</th>\n      <td>intha karutha mudija varaikum neengalum ellark...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>16157</th>\n      <td>and neenga adhiyavasiyam nu soldra apps like t...</td>\n      <td>Non_hope_speech</td>\n    </tr>\n    <tr>\n      <th>16158</th>\n      <td>daii sekram mater ku vada</td>\n      <td>Hope_speech</td>\n    </tr>\n    <tr>\n      <th>16159</th>\n      <td>bro put redmi 8 gaming</td>\n      <td>Hope_speech</td>\n    </tr>\n  </tbody>\n</table>\n<p>14200 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"label_map = {\n    \"Hope_speech\": 1,\n    \"Non_hope_speech\": 0\n}\n\ntrain[\"label\"] = train[\"label\"].map(label_map)\ndev[\"label\"]   = dev[\"label\"].map(label_map)\ntest[\"label\"]  = test[\"label\"].map(label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:34:11.074059Z","iopub.execute_input":"2026-01-04T14:34:11.074758Z","iopub.status.idle":"2026-01-04T14:34:11.084596Z","shell.execute_reply.started":"2026-01-04T14:34:11.074723Z","shell.execute_reply":"2026-01-04T14:34:11.083746Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:34:23.078589Z","iopub.execute_input":"2026-01-04T14:34:23.079405Z","iopub.status.idle":"2026-01-04T14:34:23.089443Z","shell.execute_reply.started":"2026-01-04T14:34:23.079373Z","shell.execute_reply":"2026-01-04T14:34:23.088738Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                    text  label\n1      i also don't have tiktok hello and allnbut i'm...    1.0\n2      thalaivare..neengale inum one plus mobile vach...    0.0\n3      annee varanda thondai.. corona virus affect pa...    1.0\n4                                     5views but 18likes    0.0\n5      china phone vakathiga inu evanga ellam tiktok ...    0.0\n...                                                  ...    ...\n16155                         7pm correcta erukum mg bro    1.0\n16156  intha karutha mudija varaikum neengalum ellark...    0.0\n16157  and neenga adhiyavasiyam nu soldra apps like t...    0.0\n16158                          daii sekram mater ku vada    1.0\n16159                             bro put redmi 8 gaming    1.0\n\n[14200 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>i also don't have tiktok hello and allnbut i'm...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thalaivare..neengale inum one plus mobile vach...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>annee varanda thondai.. corona virus affect pa...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5views but 18likes</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>china phone vakathiga inu evanga ellam tiktok ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16155</th>\n      <td>7pm correcta erukum mg bro</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16156</th>\n      <td>intha karutha mudija varaikum neengalum ellark...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16157</th>\n      <td>and neenga adhiyavasiyam nu soldra apps like t...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16158</th>\n      <td>daii sekram mater ku vada</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16159</th>\n      <td>bro put redmi 8 gaming</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14200 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"train_texts = train[\"text\"].tolist()\ndev_texts   = dev[\"text\"].tolist()\ntest_texts  = test[\"text\"].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:38:52.434546Z","iopub.execute_input":"2026-01-04T14:38:52.435070Z","iopub.status.idle":"2026-01-04T14:38:52.442149Z","shell.execute_reply.started":"2026-01-04T14:38:52.435021Z","shell.execute_reply":"2026-01-04T14:38:52.441441Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\nfrom sentence_transformers import SentenceTransformer\n\nmpnet_model = SentenceTransformer('all-mpnet-base-v2', device=device)\n\ntrain_mpnet = mpnet_model.encode(train_texts, batch_size=32, show_progress_bar=True)\ndev_mpnet   = mpnet_model.encode(dev_texts, batch_size=32)\ntest_mpnet  = mpnet_model.encode(test_texts, batch_size=32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:40:02.042181Z","iopub.execute_input":"2026-01-04T14:40:02.042906Z","iopub.status.idle":"2026-01-04T14:40:38.633107Z","shell.execute_reply.started":"2026-01-04T14:40:02.042876Z","shell.execute_reply":"2026-01-04T14:40:38.632448Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/444 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5377e5f1579b4325807eedec29bb5bb5"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nimport torch.nn.functional as F\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nindic_model_path = \"/kaggle/input/indic-bert/indic-bert\"  # update path\n\nindic_tokenizer = AutoTokenizer.from_pretrained(indic_model_path)\nindic_model = AutoModel.from_pretrained(indic_model_path).to(device)\nindic_model.eval()\n\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output.last_hidden_state\n    mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * mask, dim=1) / torch.clamp(mask.sum(dim=1), min=1e-9)\n\ndef extract_indicbert_embeddings(texts, batch_size=32):\n    all_embeddings = []\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        encoded = indic_tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n        encoded = {k: v.to(device) for k, v in encoded.items()}\n        with torch.no_grad():\n            output = indic_model(**encoded)\n        embeddings = mean_pooling(output, encoded[\"attention_mask\"])\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        all_embeddings.append(embeddings.cpu())\n    return torch.cat(all_embeddings).numpy()\n\n# Extract embeddings\ntrain_indic_emb = extract_indicbert_embeddings(train_texts)\ndev_indic_emb   = extract_indicbert_embeddings(dev_texts)\ntest_indic_emb  = extract_indicbert_embeddings(test_texts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:41:20.861555Z","iopub.execute_input":"2026-01-04T14:41:20.862342Z","iopub.status.idle":"2026-01-04T14:42:54.456852Z","shell.execute_reply.started":"2026-01-04T14:41:20.862309Z","shell.execute_reply":"2026-01-04T14:42:54.456111Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#CNN(AGNOSTIC)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass HopeSpeechCNN(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n\n        self.fc1 = nn.Linear(input_dim, input_dim)\n        self.dropout = nn.Dropout(0.25)\n\n        self.conv1 = nn.Conv1d(1, 64, kernel_size=5)\n        self.pool1 = nn.MaxPool1d(4)\n\n        self.conv2 = nn.Conv1d(64, 64, kernel_size=5)\n        self.pool2 = nn.MaxPool1d(4)\n\n        self.conv3 = nn.Conv1d(64, 64, kernel_size=5)\n        self.pool3 = nn.MaxPool1d(4)\n\n        # Dynamically compute output size\n        self._dummy_forward(input_dim)\n\n        self.fc_out = nn.Linear(self.flatten_dim, 2)\n\n    def _dummy_forward(self, input_dim):\n        with torch.no_grad():\n            x = torch.zeros(1, input_dim)\n            x = x.unsqueeze(1)\n            x = self.pool1(F.relu(self.conv1(x)))\n            x = self.pool2(F.relu(self.conv2(x)))\n            x = self.pool3(F.relu(self.conv3(x)))\n            self.flatten_dim = x.numel()\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n\n        x = x.unsqueeze(1)\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n\n        x = x.view(x.size(0), -1)\n        return self.fc_out(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:45:03.610110Z","iopub.execute_input":"2026-01-04T14:45:03.610465Z","iopub.status.idle":"2026-01-04T14:45:03.618822Z","shell.execute_reply.started":"2026-01-04T14:45:03.610437Z","shell.execute_reply":"2026-01-04T14:45:03.618193Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\nimport torch.optim as optim\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef evaluate(model, loader,device):\n    model.eval()\n    preds, labels = [], []\n\n    with torch.no_grad():\n        for X, y in loader:\n            X, y = X.to(device), y.to(device)\n            logits = model(X)\n            pred = torch.argmax(logits, dim=1)\n\n            preds.extend(pred.cpu().numpy())\n            labels.extend(y.cpu().numpy())\n\n    acc = accuracy_score(labels, preds)\n    macro_f1 = f1_score(labels, preds, average=\"macro\")\n    return acc, macro_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:45:20.085365Z","iopub.execute_input":"2026-01-04T14:45:20.085703Z","iopub.status.idle":"2026-01-04T14:45:20.091536Z","shell.execute_reply.started":"2026-01-04T14:45:20.085649Z","shell.execute_reply":"2026-01-04T14:45:20.090822Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def train_model(\n    model,\n    train_loader,\n    dev_loader,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"model\",\n    device=\"cuda\"\n):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    best_f1 = 0.0\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        for X, y in train_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            optimizer.zero_grad()\n            logits = model(X)\n            loss = criterion(logits, y)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n\n        dev_acc, dev_f1 = evaluate(model, dev_loader, device)\n\n        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n        print(f\"Train Loss: {avg_loss:.4f}\")\n        print(f\"Dev Acc   : {dev_acc:.4f}\")\n        print(f\"Dev F1    : {dev_f1:.4f}\")\n\n        if dev_f1 > best_f1:\n            best_f1 = dev_f1\n            torch.save(model.state_dict(), f\"{model_name}.pt\")\n            print(\" Best model saved\")\n\n    print(f\"\\n Best Dev Macro-F1 ({model_name}): {best_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:45:43.509329Z","iopub.execute_input":"2026-01-04T14:45:43.509876Z","iopub.status.idle":"2026-01-04T14:45:43.516244Z","shell.execute_reply.started":"2026-01-04T14:45:43.509844Z","shell.execute_reply":"2026-01-04T14:45:43.515514Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\n\ndef make_loaders(train_emb, dev_emb, test_emb, y_train, y_dev, y_test, batch_size=32):\n\n    train_ds = TensorDataset(\n        torch.tensor(train_emb, dtype=torch.float32),\n        torch.tensor(y_train, dtype=torch.long)\n    )\n\n    dev_ds = TensorDataset(\n        torch.tensor(dev_emb, dtype=torch.float32),\n        torch.tensor(y_dev, dtype=torch.long)\n    )\n\n    test_ds = TensorDataset(\n        torch.tensor(test_emb, dtype=torch.float32),\n        torch.tensor(y_test, dtype=torch.long)\n    )\n\n    return (\n        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n        DataLoader(dev_ds, batch_size=batch_size),\n        DataLoader(test_ds, batch_size=batch_size)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:46:02.505349Z","iopub.execute_input":"2026-01-04T14:46:02.506062Z","iopub.status.idle":"2026-01-04T14:46:02.511297Z","shell.execute_reply.started":"2026-01-04T14:46:02.506031Z","shell.execute_reply":"2026-01-04T14:46:02.510432Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"y_train = train[\"label\"].astype(int).tolist()\ny_dev   = dev[\"label\"].astype(int).tolist()\ny_test  = test[\"label\"].astype(int).tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:57:46.425996Z","iopub.execute_input":"2026-01-04T14:57:46.426595Z","iopub.status.idle":"2026-01-04T14:57:46.431589Z","shell.execute_reply.started":"2026-01-04T14:57:46.426564Z","shell.execute_reply":"2026-01-04T14:57:46.430871Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"#mpnet-cnn\ntrain_loader_mpnet, dev_loader_mpnet, test_loader_mpnet = make_loaders(\n    train_mpnet, dev_mpnet, test_mpnet,\n    y_train, y_dev, y_test\n)\n\nmodel_mpnet = HopeSpeechCNN(input_dim=768).to(device)\n\ntrain_model(\n    model_mpnet,\n    train_loader_mpnet,\n    dev_loader_mpnet,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_mpnet_tamil\",\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:58:05.936888Z","iopub.execute_input":"2026-01-04T14:58:05.937195Z","iopub.status.idle":"2026-01-04T14:58:19.469651Z","shell.execute_reply.started":"2026-01-04T14:58:05.937167Z","shell.execute_reply":"2026-01-04T14:58:19.468973Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.6857\nDev Acc   : 0.5690\nDev F1    : 0.3626\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.6562\nDev Acc   : 0.6231\nDev F1    : 0.5891\n Best model saved\n\nEpoch 3/10\nTrain Loss: 0.6382\nDev Acc   : 0.6328\nDev F1    : 0.6146\n Best model saved\n\nEpoch 4/10\nTrain Loss: 0.6283\nDev Acc   : 0.6306\nDev F1    : 0.6158\n Best model saved\n\nEpoch 5/10\nTrain Loss: 0.6198\nDev Acc   : 0.6323\nDev F1    : 0.6084\n\nEpoch 6/10\nTrain Loss: 0.6084\nDev Acc   : 0.6420\nDev F1    : 0.6063\n\nEpoch 7/10\nTrain Loss: 0.5931\nDev Acc   : 0.6351\nDev F1    : 0.6229\n Best model saved\n\nEpoch 8/10\nTrain Loss: 0.5725\nDev Acc   : 0.6266\nDev F1    : 0.6114\n\nEpoch 9/10\nTrain Loss: 0.5421\nDev Acc   : 0.6288\nDev F1    : 0.6064\n\nEpoch 10/10\nTrain Loss: 0.5094\nDev Acc   : 0.6186\nDev F1    : 0.5991\n\n Best Dev Macro-F1 (cnn_mpnet_tamil): 0.6229\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Create DataLoaders for IndicBERT embeddings\ntrain_loader_indic, dev_loader_indic, test_loader_indic = make_loaders(\n    train_indic_emb, dev_indic_emb, test_indic_emb,\n    y_train, y_dev, y_test\n)\n\n# Initialize model\nmodel_indic = HopeSpeechCNN(input_dim=768).to(device)\n\n# Train model\ntrain_model(\n    model_indic,\n    train_loader_indic,\n    dev_loader_indic,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_indicbert_tamil\",\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T14:59:19.259102Z","iopub.execute_input":"2026-01-04T14:59:19.259941Z","iopub.status.idle":"2026-01-04T14:59:32.122583Z","shell.execute_reply.started":"2026-01-04T14:59:19.259908Z","shell.execute_reply":"2026-01-04T14:59:32.121781Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.6870\nDev Acc   : 0.5690\nDev F1    : 0.3626\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.6769\nDev Acc   : 0.5975\nDev F1    : 0.5594\n Best model saved\n\nEpoch 3/10\nTrain Loss: 0.6602\nDev Acc   : 0.6106\nDev F1    : 0.5894\n Best model saved\n\nEpoch 4/10\nTrain Loss: 0.6531\nDev Acc   : 0.6311\nDev F1    : 0.5966\n Best model saved\n\nEpoch 5/10\nTrain Loss: 0.6475\nDev Acc   : 0.6226\nDev F1    : 0.5889\n\nEpoch 6/10\nTrain Loss: 0.6448\nDev Acc   : 0.6334\nDev F1    : 0.5985\n Best model saved\n\nEpoch 7/10\nTrain Loss: 0.6407\nDev Acc   : 0.6135\nDev F1    : 0.5980\n\nEpoch 8/10\nTrain Loss: 0.6372\nDev Acc   : 0.6163\nDev F1    : 0.6039\n Best model saved\n\nEpoch 9/10\nTrain Loss: 0.6332\nDev Acc   : 0.6192\nDev F1    : 0.6020\n\nEpoch 10/10\nTrain Loss: 0.6306\nDev Acc   : 0.6431\nDev F1    : 0.6157\n Best model saved\n\n Best Dev Macro-F1 (cnn_indicbert_tamil): 0.6157\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import numpy as np\n\n# Make sure the order of samples matches\nX_train_fused = np.concatenate([train_mpnet, train_indic_emb], axis=1)\nX_dev_fused   = np.concatenate([dev_mpnet, dev_indic_emb], axis=1)\nX_test_fused  = np.concatenate([test_mpnet, test_indic_emb], axis=1)\n\nprint(\"Fused train shape:\", X_train_fused.shape)\nprint(\"Fused dev shape  :\", X_dev_fused.shape)\nprint(\"Fused test shape :\", X_test_fused.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:00:08.089207Z","iopub.execute_input":"2026-01-04T15:00:08.089522Z","iopub.status.idle":"2026-01-04T15:00:08.134290Z","shell.execute_reply.started":"2026-01-04T15:00:08.089494Z","shell.execute_reply":"2026-01-04T15:00:08.133696Z"}},"outputs":[{"name":"stdout","text":"Fused train shape: (14186, 1536)\nFused dev shape  : (1754, 1536)\nFused test shape : (1760, 1536)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Create loaders for fused embeddings\ntrain_loader_fused, dev_loader_fused, test_loader_fused = make_loaders(\n    X_train_fused, X_dev_fused, X_test_fused,\n    y_train, y_dev, y_test\n)\ninput_dim = X_train_fused.shape[1]  # 768 + 768 = 1536\n\nmodel_fused = HopeSpeechCNN(input_dim=input_dim).to(device)\ntrain_model(\n    model_fused,\n    train_loader_fused,\n    dev_loader_fused,\n    epochs=10,\n    lr=1e-4,\n    model_name=\"cnn_fused_mpnet_indic_tamil\",\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:02:22.073228Z","iopub.execute_input":"2026-01-04T15:02:22.073569Z","iopub.status.idle":"2026-01-04T15:02:40.396270Z","shell.execute_reply.started":"2026-01-04T15:02:22.073540Z","shell.execute_reply":"2026-01-04T15:02:40.395608Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 0.6833\nDev Acc   : 0.6083\nDev F1    : 0.4679\n Best model saved\n\nEpoch 2/10\nTrain Loss: 0.6501\nDev Acc   : 0.6203\nDev F1    : 0.6032\n Best model saved\n\nEpoch 3/10\nTrain Loss: 0.6347\nDev Acc   : 0.6306\nDev F1    : 0.6045\n Best model saved\n\nEpoch 4/10\nTrain Loss: 0.6258\nDev Acc   : 0.6385\nDev F1    : 0.6057\n Best model saved\n\nEpoch 5/10\nTrain Loss: 0.6190\nDev Acc   : 0.6448\nDev F1    : 0.5958\n\nEpoch 6/10\nTrain Loss: 0.6102\nDev Acc   : 0.6442\nDev F1    : 0.6160\n Best model saved\n\nEpoch 7/10\nTrain Loss: 0.6013\nDev Acc   : 0.6477\nDev F1    : 0.6077\n\nEpoch 8/10\nTrain Loss: 0.5898\nDev Acc   : 0.6220\nDev F1    : 0.6089\n\nEpoch 9/10\nTrain Loss: 0.5741\nDev Acc   : 0.6300\nDev F1    : 0.6240\n Best model saved\n\nEpoch 10/10\nTrain Loss: 0.5508\nDev Acc   : 0.6243\nDev F1    : 0.6197\n\n Best Dev Macro-F1 (cnn_fused_mpnet_indic_tamil): 0.6240\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n    classification_report\n)\nimport torch\nimport numpy as np\n\ndef evaluate_on_test(model, test_loader, device):\n    model.eval()\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for x, y in test_loader:\n            x = x.to(device)\n            y = y.to(device)\n\n            logits = model(x)\n            preds = torch.argmax(logits, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y.cpu().numpy())\n\n    acc = accuracy_score(all_labels, all_preds)\n    f1  = f1_score(all_labels, all_preds, average=\"macro\")\n    prec = precision_score(all_labels, all_preds, average=\"macro\")\n    rec  = recall_score(all_labels, all_preds, average=\"macro\")\n\n    print(\"Accuracy      :\", round(acc, 4))\n    print(\"Macro-F1      :\", round(f1, 4))\n    print(\"Macro-Precision:\", round(prec, 4))\n    print(\"Macro-Recall  :\", round(rec, 4))\n    print(\"\\nClassification Report:\\n\")\n    print(classification_report(all_labels, all_preds, digits=4))\n\n    return acc, f1, prec, rec","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:03:09.364933Z","iopub.execute_input":"2026-01-04T15:03:09.365704Z","iopub.status.idle":"2026-01-04T15:03:09.371908Z","shell.execute_reply.started":"2026-01-04T15:03:09.365647Z","shell.execute_reply":"2026-01-04T15:03:09.371285Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# MPNet TEST EVALUATION\n\nmodel_mpnet = HopeSpeechCNN(input_dim=768).to(device)\nmodel_mpnet.load_state_dict(torch.load(\"cnn_mpnet_tamil.pt\"))\nmodel_mpnet.to(device)\n\nevaluate_on_test(model_mpnet, test_loader_mpnet, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:03:37.910229Z","iopub.execute_input":"2026-01-04T15:03:37.910503Z","iopub.status.idle":"2026-01-04T15:03:38.023196Z","shell.execute_reply.started":"2026-01-04T15:03:37.910479Z","shell.execute_reply":"2026-01-04T15:03:38.022573Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.6295\nMacro-F1      : 0.6206\nMacro-Precision: 0.6277\nMacro-Recall  : 0.6215\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.6356    0.7283    0.6788       946\n           1     0.6198    0.5147    0.5624       814\n\n    accuracy                         0.6295      1760\n   macro avg     0.6277    0.6215    0.6206      1760\nweighted avg     0.6283    0.6295    0.6250      1760\n\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(0.6295454545454545, 0.620616920686349, 0.6277156706478307, 0.6215359122335866)"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# INDICBERT TEST EVALUATION\n\nmodel_indic = HopeSpeechCNN(input_dim=768).to(device)\nmodel_indic.load_state_dict(torch.load(\"cnn_indicbert_tamil.pt\"))\nmodel_indic.to(device)\n\nevaluate_on_test(model_indic, test_loader_indic, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:04:30.390332Z","iopub.execute_input":"2026-01-04T15:04:30.390918Z","iopub.status.idle":"2026-01-04T15:04:30.501591Z","shell.execute_reply.started":"2026-01-04T15:04:30.390887Z","shell.execute_reply":"2026-01-04T15:04:30.500865Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.621\nMacro-F1      : 0.5983\nMacro-Precision: 0.6263\nMacro-Recall  : 0.6066\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.6131    0.7992    0.6939       946\n           1     0.6395    0.4140    0.5026       814\n\n    accuracy                         0.6210      1760\n   macro avg     0.6263    0.6066    0.5983      1760\nweighted avg     0.6253    0.6210    0.6054      1760\n\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(0.6210227272727272, 0.598253137620682, 0.6263036884167371, 0.6065796240214845)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"# FUSION TEST EVALUATION\nmodel_fusion = HopeSpeechCNN(input_dim=768*2).to(device)\nmodel_fusion.load_state_dict(torch.load(\"cnn_fused_mpnet_indic_tamil.pt\"))\n\nevaluate_on_test(model_fusion, test_loader_fused , device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:07:35.973194Z","iopub.execute_input":"2026-01-04T15:07:35.973835Z","iopub.status.idle":"2026-01-04T15:07:36.122763Z","shell.execute_reply.started":"2026-01-04T15:07:35.973802Z","shell.execute_reply":"2026-01-04T15:07:36.122137Z"}},"outputs":[{"name":"stdout","text":"Accuracy      : 0.6205\nMacro-F1      : 0.6162\nMacro-Precision: 0.6175\nMacro-Recall  : 0.616\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n           0     0.6390    0.6755    0.6567       946\n           1     0.5961    0.5565    0.5756       814\n\n    accuracy                         0.6205      1760\n   macro avg     0.6175    0.6160    0.6162      1760\nweighted avg     0.6191    0.6205    0.6192      1760\n\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(0.6204545454545455,\n 0.6161676576328337,\n 0.6175263157894737,\n 0.6159933718073253)"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"results = {}\ndef evaluate_and_store(name, model, dev_loader, test_loader, device):\n    from sklearn.metrics import f1_score\n    import torch\n\n    def eval_loader(loader):\n        model.eval()\n        preds, labels = [], []\n\n        with torch.no_grad():\n            for x, y in loader:\n                x = x.to(device)\n                y = y.to(device)\n\n                logits = model(x)\n                preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n                labels.extend(y.cpu().numpy())\n\n        return f1_score(labels, preds, average=\"macro\")\n\n    dev_f1  = eval_loader(dev_loader)\n    test_f1 = eval_loader(test_loader)\n\n    results[name] = {\n        \"Dev Macro-F1\": round(dev_f1, 4),\n        \"Test Macro-F1\": round(test_f1, 4)\n    }\n\n    print(name)\n    print(\" Dev Macro-F1 :\", round(dev_f1, 4))\n    print(\" Test Macro-F1:\", round(test_f1, 4))\n    print(\"-\" * 40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:08:27.053090Z","iopub.execute_input":"2026-01-04T15:08:27.053644Z","iopub.status.idle":"2026-01-04T15:08:27.059638Z","shell.execute_reply.started":"2026-01-04T15:08:27.053614Z","shell.execute_reply":"2026-01-04T15:08:27.058812Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"model_mpnet = HopeSpeechCNN(input_dim=768).to(device)\nmodel_mpnet.load_state_dict(torch.load(\"cnn_mpnet_tamil.pt\"))\n\nevaluate_and_store(\n    \"MPNet-CNN\",\n    model_mpnet,\n    dev_loader_mpnet,\n    test_loader_mpnet,\n    device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:08:58.334936Z","iopub.execute_input":"2026-01-04T15:08:58.335232Z","iopub.status.idle":"2026-01-04T15:08:58.500239Z","shell.execute_reply.started":"2026-01-04T15:08:58.335205Z","shell.execute_reply":"2026-01-04T15:08:58.499616Z"}},"outputs":[{"name":"stdout","text":"MPNet-CNN\n Dev Macro-F1 : 0.6229\n Test Macro-F1: 0.6206\n----------------------------------------\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"model_indic = HopeSpeechCNN(input_dim=768).to(device)\nmodel_indic.load_state_dict(torch.load(\"cnn_indicbert_tamil.pt\"))\n\nevaluate_and_store(\n    \"IndicBERT-CNN\",\n    model_indic,\n    dev_loader_indic,\n    test_loader_indic,\n    device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:09:16.742047Z","iopub.execute_input":"2026-01-04T15:09:16.742347Z","iopub.status.idle":"2026-01-04T15:09:16.905996Z","shell.execute_reply.started":"2026-01-04T15:09:16.742320Z","shell.execute_reply":"2026-01-04T15:09:16.905441Z"}},"outputs":[{"name":"stdout","text":"IndicBERT-CNN\n Dev Macro-F1 : 0.6157\n Test Macro-F1: 0.5983\n----------------------------------------\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"model_indic = HopeSpeechCNN(input_dim=768*2).to(device)\nmodel_indic.load_state_dict(torch.load(\"/kaggle/working/cnn_fused_mpnet_indic_tamil.pt\"))\n\nevaluate_and_store(\n    \"FUSION-CNN\",\n    model_fusion,\n    dev_loader_fused,\n    test_loader_fused,\n    device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:10:25.394221Z","iopub.execute_input":"2026-01-04T15:10:25.394896Z","iopub.status.idle":"2026-01-04T15:10:25.621817Z","shell.execute_reply.started":"2026-01-04T15:10:25.394863Z","shell.execute_reply":"2026-01-04T15:10:25.621116Z"}},"outputs":[{"name":"stdout","text":"FUSION-CNN\n Dev Macro-F1 : 0.624\n Test Macro-F1: 0.6162\n----------------------------------------\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"import pandas as pd\n\ndf_results = pd.DataFrame(results).T\ndf_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T15:10:47.754196Z","iopub.execute_input":"2026-01-04T15:10:47.754436Z","iopub.status.idle":"2026-01-04T15:10:47.769556Z","shell.execute_reply.started":"2026-01-04T15:10:47.754407Z","shell.execute_reply":"2026-01-04T15:10:47.768869Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"               Dev Macro-F1  Test Macro-F1\nMPNet-CNN            0.6229         0.6206\nIndicBERT-CNN        0.6157         0.5983\nFUSION-CNN           0.6240         0.6162","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dev Macro-F1</th>\n      <th>Test Macro-F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MPNet-CNN</th>\n      <td>0.6229</td>\n      <td>0.6206</td>\n    </tr>\n    <tr>\n      <th>IndicBERT-CNN</th>\n      <td>0.6157</td>\n      <td>0.5983</td>\n    </tr>\n    <tr>\n      <th>FUSION-CNN</th>\n      <td>0.6240</td>\n      <td>0.6162</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":52}]}